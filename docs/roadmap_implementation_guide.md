# Project Maestro: ë‹¤ìŒ ë‹¨ê³„ êµ¬í˜„ ë° ê³ ë„í™” ë¡œë“œë§µ

## ğŸ“Š í˜„ì¬ êµ¬í˜„ ìƒíƒœ ë¶„ì„

### âœ… ì™„ë£Œëœ í•µì‹¬ ê¸°ëŠ¥
- **LangGraph ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜**: ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ
- **ëŒ€í™” ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ**: 3ê³„ì¸µ ë©”ëª¨ë¦¬ ì•„í‚¤í…ì²˜ êµ¬í˜„
- **RAG ì‹œìŠ¤í…œ**: ê²Œì„ ê°œë°œ íŠ¹í™” RAG êµ¬ì¶•
- **ì—”í„°í”„ë¼ì´ì¦ˆ í†µí•©**: Jira, Slack, Confluence ì—°ë™
- **ì˜ë„ ë¶„ì„ ë° ë¼ìš°íŒ…**: ì¿¼ë¦¬ ë³µì¡ë„ ê¸°ë°˜ ìºìŠ¤ì¼€ì´ë”©

### ğŸ¯ ê°•ì 
1. ê²¬ê³ í•œ ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜
2. ê²Œì„ ê°œë°œì— íŠ¹í™”ëœ ë„ë©”ì¸ ì§€ì‹
3. ì—”í„°í”„ë¼ì´ì¦ˆ ì‹œìŠ¤í…œ í†µí•© ì™„ë£Œ
4. ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ í†µí•œ ê°œì¸í™”

### âš ï¸ ê°œì„  í•„ìš” ì˜ì—­
1. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™” ë¯¸í¡
2. ì—ì´ì „íŠ¸ ê°„ í˜‘ì—… íš¨ìœ¨ì„±
3. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
4. í”„ë¡œë•ì…˜ í™˜ê²½ ëŒ€ë¹„ ë¶€ì¡±

---

## ğŸ¨ Phase 0: í”„ë¡ íŠ¸ì—”ë“œ ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶• (1-2ì£¼)

### 0.1 IBM Carbon Design System ê¸°ë°˜ UI ì…‹ì—…
**ìš°ì„ ìˆœìœ„**: ğŸ”´ Critical  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 2ì¼

#### êµ¬í˜„ ë‚´ìš©
```typescript
// frontend/src/setup/carbon-theme.ts
import { Theme } from '@carbon/react';
import { g100 } from '@carbon/themes';

export const maestroTheme = {
  ...g100,
  // AI ì›Œí¬í”Œë¡œìš° ì‹œê°í™”ë¥¼ ìœ„í•œ ì»¤ìŠ¤í…€ í† í°
  custom: {
    agent: {
      planning: '#0f62fe',      // Blue 60
      executing: '#42be65',     // Green 40
      waiting: '#f1c21b',       // Yellow 30
      error: '#da1e28',         // Red 50
      complete: '#24a148'       // Green 50
    },
    workflow: {
      background: '#161616',    // Gray 100
      border: '#393939',        // Gray 80
      hover: '#4c4c4c'         // Gray 70
    }
  }
};

// frontend/src/components/layout/AppShell.tsx
import { 
  Header, 
  HeaderGlobalBar,
  HeaderGlobalAction,
  SideNav,
  SideNavItems,
  Content
} from '@carbon/react';
import { 
  Notification20, 
  UserAvatar20,
  Dashboard20,
  Flow20
} from '@carbon/icons-react';

export const AppShell: React.FC = ({ children }) => {
  return (
    <div className="maestro-app">
      <Header aria-label="Project Maestro">
        <HeaderName prefix="IBM">Project Maestro</HeaderName>
        <HeaderGlobalBar>
          <HeaderGlobalAction aria-label="Notifications">
            <Notification20 />
          </HeaderGlobalAction>
          <HeaderGlobalAction aria-label="User">
            <UserAvatar20 />
          </HeaderGlobalAction>
        </HeaderGlobalBar>
      </Header>
      
      <SideNav aria-label="Side navigation" expanded={true}>
        <SideNavItems>
          <SideNavLink icon={Dashboard20} href="/dashboard">
            Dashboard
          </SideNavLink>
          <SideNavLink icon={Flow20} href="/workflow">
            Workflow Monitor
          </SideNavLink>
        </SideNavItems>
      </SideNav>
      
      <Content>{children}</Content>
    </div>
  );
};
```

### 0.2 í”„ë¡¬í”„íŠ¸ ì…ë ¥ ì¸í„°í˜ì´ìŠ¤
**ìš°ì„ ìˆœìœ„**: ğŸ”´ Critical  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 3ì¼

#### êµ¬í˜„ ë‚´ìš©
```typescript
// frontend/src/components/prompt/PromptInterface.tsx
import React, { useState, useRef } from 'react';
import { 
  TextArea, 
  Button, 
  Tag,
  InlineNotification,
  FileUploader
} from '@carbon/react';
import { Send20, Add20 } from '@carbon/icons-react';
import { useWebSocket } from '@/hooks/useWebSocket';

interface PromptInterfaceProps {
  onSubmit: (prompt: PromptData) => void;
  isProcessing: boolean;
}

export const PromptInterface: React.FC<PromptInterfaceProps> = ({
  onSubmit,
  isProcessing
}) => {
  const [prompt, setPrompt] = useState('');
  const [context, setContext] = useState<File[]>([]);
  const [complexity, setComplexity] = useState<'simple' | 'moderate' | 'complex'>('moderate');
  
  // ì‹¤ì‹œê°„ ë³µì¡ë„ ë¶„ì„
  const analyzeComplexity = (text: string) => {
    const wordCount = text.split(' ').length;
    const hasCode = /```[\s\S]*?```/.test(text);
    const hasMultipleSteps = /\d+\.|step|then|after/gi.test(text);
    
    if (wordCount > 100 || hasCode || hasMultipleSteps) {
      return 'complex';
    } else if (wordCount > 50) {
      return 'moderate';
    }
    return 'simple';
  };
  
  const handlePromptChange = (e: React.ChangeEvent<HTMLTextAreaElement>) => {
    const text = e.target.value;
    setPrompt(text);
    setComplexity(analyzeComplexity(text));
  };
  
  const handleSubmit = () => {
    onSubmit({
      prompt,
      context,
      complexity,
      timestamp: new Date().toISOString()
    });
  };
  
  return (
    <div className="prompt-interface">
      <div className="prompt-header">
        <h2>AI Assistant Prompt</h2>
        <div className="complexity-indicator">
          <Tag type={
            complexity === 'simple' ? 'green' : 
            complexity === 'moderate' ? 'blue' : 'red'
          }>
            {complexity} query
          </Tag>
        </div>
      </div>
      
      <TextArea
        id="prompt-input"
        labelText="Enter your request"
        placeholder="Describe what you want to build or achieve..."
        rows={6}
        value={prompt}
        onChange={handlePromptChange}
        disabled={isProcessing}
      />
      
      <FileUploader
        labelTitle="Add Context"
        labelDescription="Upload files for additional context"
        buttonLabel="Add files"
        filenameStatus="edit"
        accept={['.txt', '.md', '.json', '.yaml', '.py', '.js', '.ts']}
        multiple
        onChange={(e) => setContext(Array.from(e.target.files || []))}
      />
      
      <div className="prompt-actions">
        <Button 
          kind="primary"
          onClick={handleSubmit}
          disabled={!prompt || isProcessing}
          renderIcon={Send20}
        >
          {isProcessing ? 'Processing...' : 'Send'}
        </Button>
        
        <Button 
          kind="ghost"
          onClick={() => {
            setPrompt('');
            setContext([]);
          }}
          disabled={isProcessing}
        >
          Clear
        </Button>
      </div>
      
      {isProcessing && (
        <InlineNotification
          kind="info"
          title="Processing"
          subtitle="Your request is being processed by the AI agents..."
          hideCloseButton
        />
      )}
    </div>
  );
};
```

### 0.3 ì—ì´ì „íŠ¸ ì§„í–‰ ìƒí™© ì‹œê°í™”
**ìš°ì„ ìˆœìœ„**: ğŸ”´ Critical  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 4ì¼

#### êµ¬í˜„ ë‚´ìš©
```typescript
// frontend/src/components/agents/AgentProgressVisualization.tsx
import React, { useEffect, useState } from 'react';
import { 
  ProgressIndicator, 
  ProgressStep,
  Tile,
  SkeletonText,
  InlineLoading,
  Tag
} from '@carbon/react';
import { CheckmarkFilled20, ErrorFilled20 } from '@carbon/icons-react';
import * as d3 from 'd3';

interface AgentState {
  id: string;
  name: string;
  status: 'idle' | 'planning' | 'executing' | 'complete' | 'error';
  progress: number;
  currentTask?: string;
  logs: string[];
  metrics: {
    tokensUsed: number;
    executionTime: number;
    memoryUsage: number;
  };
}

export const AgentProgressVisualization: React.FC<{
  agents: AgentState[];
  workflow: WorkflowState;
}> = ({ agents, workflow }) => {
  const svgRef = useRef<SVGSVGElement>(null);
  
  // D3.jsë¥¼ ì‚¬ìš©í•œ ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ì‹œê°í™”
  useEffect(() => {
    if (!svgRef.current) return;
    
    const svg = d3.select(svgRef.current);
    const width = 800;
    const height = 400;
    
    // ì—ì´ì „íŠ¸ ë…¸ë“œ ê·¸ë¦¬ê¸°
    const nodes = agents.map((agent, i) => ({
      id: agent.id,
      name: agent.name,
      status: agent.status,
      x: (i + 1) * (width / (agents.length + 1)),
      y: height / 2
    }));
    
    // ë…¸ë“œ ì—…ë°ì´íŠ¸
    const nodeSelection = svg.selectAll('.agent-node')
      .data(nodes, d => d.id);
    
    // Enter
    const nodeEnter = nodeSelection.enter()
      .append('g')
      .attr('class', 'agent-node')
      .attr('transform', d => `translate(${d.x}, ${d.y})`);
    
    nodeEnter.append('circle')
      .attr('r', 30)
      .attr('fill', d => getStatusColor(d.status))
      .attr('stroke', '#393939')
      .attr('stroke-width', 2);
    
    nodeEnter.append('text')
      .attr('text-anchor', 'middle')
      .attr('dy', 5)
      .attr('fill', 'white')
      .style('font-size', '12px')
      .text(d => d.name.substring(0, 3).toUpperCase());
    
    // Update
    nodeSelection.select('circle')
      .transition()
      .duration(500)
      .attr('fill', d => getStatusColor(d.status))
      .attr('r', d => d.status === 'executing' ? 35 : 30);
    
    // ì—°ê²°ì„  ê·¸ë¦¬ê¸°
    const links = [];
    for (let i = 0; i < nodes.length - 1; i++) {
      links.push({
        source: nodes[i],
        target: nodes[i + 1]
      });
    }
    
    const linkSelection = svg.selectAll('.agent-link')
      .data(links);
    
    linkSelection.enter()
      .append('line')
      .attr('class', 'agent-link')
      .attr('x1', d => d.source.x)
      .attr('y1', d => d.source.y)
      .attr('x2', d => d.target.x)
      .attr('y2', d => d.target.y)
      .attr('stroke', '#4c4c4c')
      .attr('stroke-width', 2)
      .attr('stroke-dasharray', '5,5');
    
  }, [agents]);
  
  const getStatusColor = (status: string) => {
    const colors = {
      idle: '#525252',
      planning: '#0f62fe',
      executing: '#42be65',
      complete: '#24a148',
      error: '#da1e28'
    };
    return colors[status] || '#525252';
  };
  
  return (
    <div className="agent-visualization">
      <div className="workflow-graph">
        <svg ref={svgRef} width="800" height="400" />
      </div>
      
      <div className="agent-details">
        {agents.map(agent => (
          <Tile key={agent.id} className="agent-tile">
            <div className="agent-header">
              <h4>{agent.name}</h4>
              <Tag type={
                agent.status === 'complete' ? 'green' :
                agent.status === 'error' ? 'red' :
                agent.status === 'executing' ? 'blue' : 'gray'
              }>
                {agent.status}
              </Tag>
            </div>
            
            {agent.status === 'executing' && (
              <InlineLoading 
                description={agent.currentTask || 'Processing...'}
              />
            )}
            
            {agent.status === 'complete' && (
              <div className="agent-metrics">
                <span>Tokens: {agent.metrics.tokensUsed}</span>
                <span>Time: {agent.metrics.executionTime}s</span>
                <span>Memory: {agent.metrics.memoryUsage}MB</span>
              </div>
            )}
            
            <div className="agent-logs">
              {agent.logs.slice(-3).map((log, i) => (
                <p key={i} className="log-entry">{log}</p>
              ))}
            </div>
          </Tile>
        ))}
      </div>
    </div>
  );
};
```

### 0.4 ì‹¤ì‹œê°„ ì›Œí¬í”Œë¡œìš° ëª¨ë‹ˆí„°ë§
**ìš°ì„ ìˆœìœ„**: ğŸ”´ Critical  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 3ì¼

#### êµ¬í˜„ ë‚´ìš©
```typescript
// frontend/src/components/monitoring/WorkflowMonitor.tsx
import React, { useEffect, useState } from 'react';
import { 
  DataTable, 
  DataTableHeader,
  StructuredListWrapper,
  StructuredListHead,
  StructuredListBody,
  StructuredListRow,
  StructuredListCell,
  ProgressBar,
  InlineNotification
} from '@carbon/react';
import { useWebSocket } from '@/hooks/useWebSocket';
import { AgentProgressVisualization } from '../agents/AgentProgressVisualization';

export const WorkflowMonitor: React.FC = () => {
  const [workflows, setWorkflows] = useState<WorkflowState[]>([]);
  const [selectedWorkflow, setSelectedWorkflow] = useState<string | null>(null);
  const [realtimeLogs, setRealtimeLogs] = useState<LogEntry[]>([]);
  
  // WebSocket ì—°ê²°ë¡œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
  const { messages, sendMessage } = useWebSocket('ws://localhost:8000/ws');
  
  useEffect(() => {
    messages.forEach(msg => {
      if (msg.type === 'workflow_update') {
        updateWorkflow(msg.data);
      } else if (msg.type === 'log_entry') {
        addLogEntry(msg.data);
      } else if (msg.type === 'agent_status') {
        updateAgentStatus(msg.data);
      }
    });
  }, [messages]);
  
  const updateWorkflow = (data: WorkflowUpdate) => {
    setWorkflows(prev => {
      const index = prev.findIndex(w => w.id === data.id);
      if (index >= 0) {
        const updated = [...prev];
        updated[index] = { ...updated[index], ...data };
        return updated;
      }
      return [...prev, data];
    });
  };
  
  const addLogEntry = (entry: LogEntry) => {
    setRealtimeLogs(prev => [...prev.slice(-99), entry]);
  };
  
  return (
    <div className="workflow-monitor">
      <div className="monitor-header">
        <h2>Workflow Monitor</h2>
        <div className="monitor-stats">
          <Tag>Active: {workflows.filter(w => w.status === 'running').length}</Tag>
          <Tag>Completed: {workflows.filter(w => w.status === 'complete').length}</Tag>
          <Tag>Failed: {workflows.filter(w => w.status === 'error').length}</Tag>
        </div>
      </div>
      
      <div className="monitor-content">
        <div className="workflows-list">
          <DataTable
            rows={workflows}
            headers={[
              { key: 'id', header: 'ID' },
              { key: 'name', header: 'Workflow' },
              { key: 'status', header: 'Status' },
              { key: 'progress', header: 'Progress' },
              { key: 'startTime', header: 'Started' }
            ]}
            render={({ rows, headers }) => (
              <TableContainer>
                <Table>
                  <TableHead>
                    <TableRow>
                      {headers.map(header => (
                        <TableHeader key={header.key}>
                          {header.header}
                        </TableHeader>
                      ))}
                    </TableRow>
                  </TableHead>
                  <TableBody>
                    {rows.map(row => (
                      <TableRow 
                        key={row.id}
                        onClick={() => setSelectedWorkflow(row.id)}
                        className={selectedWorkflow === row.id ? 'selected' : ''}
                      >
                        {row.cells.map(cell => (
                          <TableCell key={cell.id}>
                            {cell.info.header === 'progress' ? (
                              <ProgressBar value={cell.value} />
                            ) : (
                              cell.value
                            )}
                          </TableCell>
                        ))}
                      </TableRow>
                    ))}
                  </TableBody>
                </Table>
              </TableContainer>
            )}
          />
        </div>
        
        {selectedWorkflow && (
          <div className="workflow-details">
            <AgentProgressVisualization
              agents={getWorkflowAgents(selectedWorkflow)}
              workflow={workflows.find(w => w.id === selectedWorkflow)}
            />
          </div>
        )}
        
        <div className="realtime-logs">
          <h3>Real-time Logs</h3>
          <StructuredListWrapper>
            <StructuredListBody>
              {realtimeLogs.map((log, i) => (
                <StructuredListRow key={i}>
                  <StructuredListCell>
                    <span className="log-timestamp">{log.timestamp}</span>
                  </StructuredListCell>
                  <StructuredListCell>
                    <Tag type={log.level}>{log.agent}</Tag>
                  </StructuredListCell>
                  <StructuredListCell>
                    {log.message}
                  </StructuredListCell>
                </StructuredListRow>
              ))}
            </StructuredListBody>
          </StructuredListWrapper>
        </div>
      </div>
    </div>
  );
};
```

## ğŸš€ Phase 1: ì¦‰ì‹œ êµ¬í˜„ ê°€ëŠ¥í•œ ê°œì„ ì‚¬í•­ (1-2ì£¼)

### 1.1 Observable LangGraph êµ¬í˜„
**ìš°ì„ ìˆœìœ„**: ğŸ”´ Critical  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 3ì¼

#### êµ¬í˜„ ë‚´ìš©
```python
# src/project_maestro/core/observable_orchestrator.py
from langfuse import Langfuse
from langgraph.graph import StateGraph
import structlog

class ObservableLangGraphOrchestrator:
    """ê´€ì°° ê°€ëŠ¥í•œ LangGraph ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""
    
    def __init__(self):
        self.langfuse = Langfuse()
        self.logger = structlog.get_logger()
        self.metrics = PrometheusMetrics()
        
    async def execute_with_tracing(self, request: str):
        """ì¶”ì  ê¸°ëŠ¥ì´ ìˆëŠ” ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        trace = self.langfuse.trace(name="workflow_execution")
        
        # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
        with self.metrics.timer("workflow_execution_time"):
            # ê° ì—ì´ì „íŠ¸ í˜¸ì¶œ ì¶”ì 
            async for event in self.graph.astream_events(request):
                self.logger.info("agent_event", 
                    agent=event.agent_name,
                    action=event.action,
                    latency=event.latency
                )
                trace.span(name=f"agent_{event.agent_name}")
```

#### ê¸°ëŒ€ íš¨ê³¼
- ì‹¤ì‹œê°„ ì›Œí¬í”Œë¡œìš° ëª¨ë‹ˆí„°ë§
- ë³‘ëª© ì§€ì  ì‹ë³„ ë° ìµœì í™”
- ì—ì´ì „íŠ¸ ì„±ëŠ¥ ì¶”ì 

### 1.2 ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìµœì í™”
**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ Important  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 2ì¼

#### êµ¬í˜„ ë‚´ìš©
```python
# src/project_maestro/core/streaming_handler.py
from typing import AsyncIterator
import asyncio

class StreamingResponseHandler:
    """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìµœì í™” í•¸ë“¤ëŸ¬"""
    
    async def stream_with_buffering(
        self, 
        agent_response: AsyncIterator[str],
        buffer_size: int = 10
    ):
        """ë²„í¼ë§ì„ í†µí•œ ìŠ¤íŠ¸ë¦¬ë° ìµœì í™”"""
        buffer = []
        async for chunk in agent_response:
            buffer.append(chunk)
            
            if len(buffer) >= buffer_size:
                yield ''.join(buffer)
                buffer = []
        
        if buffer:
            yield ''.join(buffer)
    
    async def parallel_stream_merge(
        self,
        streams: List[AsyncIterator]
    ):
        """ì—¬ëŸ¬ ìŠ¤íŠ¸ë¦¼ì„ ë³‘í•©í•˜ì—¬ ì²˜ë¦¬"""
        async def consume_stream(stream, queue):
            async for item in stream:
                await queue.put(item)
            await queue.put(None)
        
        queue = asyncio.Queue()
        tasks = [
            asyncio.create_task(consume_stream(s, queue)) 
            for s in streams
        ]
        
        finished = 0
        while finished < len(streams):
            item = await queue.get()
            if item is None:
                finished += 1
            else:
                yield item
```

### 1.3 ì—ì´ì „íŠ¸ í˜‘ì—… í”„ë¡œí† ì½œ ê°•í™”
**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ Important  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 3ì¼

#### êµ¬í˜„ ë‚´ìš©
```python
# src/project_maestro/core/agent_collaboration.py
from dataclasses import dataclass
from enum import Enum

class CollaborationType(Enum):
    SEQUENTIAL = "sequential"
    PARALLEL = "parallel"
    HIERARCHICAL = "hierarchical"
    CONSENSUS = "consensus"

@dataclass
class CollaborationProtocol:
    """ì—ì´ì „íŠ¸ ê°„ í˜‘ì—… í”„ë¡œí† ì½œ"""
    
    type: CollaborationType
    agents: List[str]
    coordination_rules: Dict[str, Any]
    conflict_resolution: str
    
class EnhancedAgentCollaboration:
    """í–¥ìƒëœ ì—ì´ì „íŠ¸ í˜‘ì—… ì‹œìŠ¤í…œ"""
    
    async def negotiate_task_distribution(
        self,
        task: Dict,
        available_agents: List[Agent]
    ) -> Dict[str, List[Task]]:
        """ì‘ì—… ë¶„ë°° í˜‘ìƒ"""
        # ê° ì—ì´ì „íŠ¸ì˜ ëŠ¥ë ¥ í‰ê°€
        capabilities = await self._assess_capabilities(available_agents)
        
        # ì‘ì—… ë³µì¡ë„ ë¶„ì„
        task_complexity = await self._analyze_task_complexity(task)
        
        # ìµœì  ë¶„ë°° ê³„ì‚°
        distribution = self._optimize_distribution(
            capabilities, 
            task_complexity
        )
        
        return distribution
    
    async def consensus_decision(
        self,
        agents: List[Agent],
        proposal: Dict
    ) -> Dict:
        """í•©ì˜ ê¸°ë°˜ ì˜ì‚¬ê²°ì •"""
        votes = []
        
        # ê° ì—ì´ì „íŠ¸ì˜ íˆ¬í‘œ ìˆ˜ì§‘
        for agent in agents:
            vote = await agent.evaluate_proposal(proposal)
            votes.append({
                'agent': agent.name,
                'decision': vote.decision,
                'confidence': vote.confidence,
                'reasoning': vote.reasoning
            })
        
        # ê°€ì¤‘ íˆ¬í‘œ ì§‘ê³„
        return self._aggregate_votes(votes)
```

---

## ğŸ”Œ Phase 1.5: ë°±ì—”ë“œ API í†µí•© (3-4ì¼)

### 1.5.1 FastAPI WebSocket ì—”ë“œí¬ì¸íŠ¸
**ìš°ì„ ìˆœìœ„**: ğŸ”´ Critical  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 2ì¼

#### êµ¬í˜„ ë‚´ìš©
```python
# src/project_maestro/api/websocket_manager.py
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from typing import Dict, List
import asyncio
import json

class ConnectionManager:
    """WebSocket ì—°ê²° ê´€ë¦¬ì"""
    
    def __init__(self):
        self.active_connections: List[WebSocket] = []
        self.user_sessions: Dict[str, WebSocket] = {}
        
    async def connect(self, websocket: WebSocket, user_id: str):
        await websocket.accept()
        self.active_connections.append(websocket)
        self.user_sessions[user_id] = websocket
        
    def disconnect(self, websocket: WebSocket, user_id: str):
        self.active_connections.remove(websocket)
        if user_id in self.user_sessions:
            del self.user_sessions[user_id]
            
    async def send_personal_message(self, message: dict, user_id: str):
        if user_id in self.user_sessions:
            websocket = self.user_sessions[user_id]
            await websocket.send_json(message)
            
    async def broadcast(self, message: dict):
        for connection in self.active_connections:
            await connection.send_json(message)

# src/project_maestro/api/streaming_endpoints.py
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from fastapi.responses import StreamingResponse
import asyncio

router = APIRouter(prefix="/api/v1")
manager = ConnectionManager()

@router.websocket("/ws/{user_id}")
async def websocket_endpoint(websocket: WebSocket, user_id: str):
    await manager.connect(websocket, user_id)
    
    try:
        while True:
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ 
            data = await websocket.receive_json()
            
            if data['type'] == 'prompt_submission':
                # ì›Œí¬í”Œë¡œìš° ì‹œì‘
                workflow_id = await start_workflow(data['prompt'])
                
                # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ìŠ¤íŠ¸ë¦¬ë°
                async for update in process_workflow_with_updates(workflow_id):
                    await manager.send_personal_message({
                        'type': 'workflow_update',
                        'data': update
                    }, user_id)
                    
            elif data['type'] == 'agent_action':
                # ì—ì´ì „íŠ¸ ì•¡ì…˜ ì²˜ë¦¬
                result = await handle_agent_action(data['action'])
                await manager.send_personal_message({
                    'type': 'action_result',
                    'data': result
                }, user_id)
                
    except WebSocketDisconnect:
        manager.disconnect(websocket, user_id)
        
async def process_workflow_with_updates(workflow_id: str):
    """ì›Œí¬í”Œë¡œìš° ì²˜ë¦¬ ì¤‘ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ìƒì„±"""
    
    orchestrator = LangGraphOrchestrator()
    
    async for event in orchestrator.astream_events(workflow_id):
        yield {
            'workflow_id': workflow_id,
            'event_type': event.type,
            'agent': event.agent_name,
            'status': event.status,
            'progress': event.progress,
            'logs': event.logs,
            'timestamp': datetime.now().isoformat()
        }

@router.post("/stream/workflow")
async def stream_workflow(request: WorkflowRequest):
    """Server-Sent Eventsë¥¼ í†µí•œ ì›Œí¬í”Œë¡œìš° ìŠ¤íŠ¸ë¦¬ë°"""
    
    async def generate():
        workflow_id = await start_workflow(request.prompt)
        
        async for update in process_workflow_with_updates(workflow_id):
            yield f"data: {json.dumps(update)}\n\n"
            
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )
```

### 1.5.2 í”„ë¡ íŠ¸ì—”ë“œ API í†µí•© í›…
**ìš°ì„ ìˆœìœ„**: ğŸ”´ Critical  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 2ì¼

#### êµ¬í˜„ ë‚´ìš©
```typescript
// frontend/src/hooks/useWebSocket.ts
import { useEffect, useState, useCallback, useRef } from 'react';

interface WebSocketMessage {
  type: string;
  data: any;
}

export const useWebSocket = (url: string) => {
  const [messages, setMessages] = useState<WebSocketMessage[]>([]);
  const [isConnected, setIsConnected] = useState(false);
  const [error, setError] = useState<Error | null>(null);
  const ws = useRef<WebSocket | null>(null);
  const reconnectTimeout = useRef<NodeJS.Timeout>();
  
  const connect = useCallback(() => {
    try {
      ws.current = new WebSocket(url);
      
      ws.current.onopen = () => {
        setIsConnected(true);
        setError(null);
        console.log('WebSocket connected');
      };
      
      ws.current.onmessage = (event) => {
        const message = JSON.parse(event.data);
        setMessages(prev => [...prev, message]);
      };
      
      ws.current.onerror = (error) => {
        setError(new Error('WebSocket error'));
        console.error('WebSocket error:', error);
      };
      
      ws.current.onclose = () => {
        setIsConnected(false);
        // ìë™ ì¬ì—°ê²°
        reconnectTimeout.current = setTimeout(() => {
          connect();
        }, 3000);
      };
    } catch (err) {
      setError(err as Error);
    }
  }, [url]);
  
  const sendMessage = useCallback((message: WebSocketMessage) => {
    if (ws.current && ws.current.readyState === WebSocket.OPEN) {
      ws.current.send(JSON.stringify(message));
    }
  }, []);
  
  const disconnect = useCallback(() => {
    if (reconnectTimeout.current) {
      clearTimeout(reconnectTimeout.current);
    }
    if (ws.current) {
      ws.current.close();
    }
  }, []);
  
  useEffect(() => {
    connect();
    return () => disconnect();
  }, [connect, disconnect]);
  
  return {
    messages,
    sendMessage,
    isConnected,
    error,
    disconnect
  };
};

// frontend/src/hooks/useWorkflowAPI.ts
import { useState, useCallback } from 'react';
import axios from 'axios';

export const useWorkflowAPI = () => {
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<Error | null>(null);
  
  const submitPrompt = useCallback(async (prompt: string, context?: any) => {
    setLoading(true);
    setError(null);
    
    try {
      const response = await axios.post('/api/v1/workflow/submit', {
        prompt,
        context,
        user_id: getUserId(),
        timestamp: new Date().toISOString()
      });
      
      return response.data;
    } catch (err) {
      setError(err as Error);
      throw err;
    } finally {
      setLoading(false);
    }
  }, []);
  
  const getWorkflowStatus = useCallback(async (workflowId: string) => {
    const response = await axios.get(`/api/v1/workflow/${workflowId}/status`);
    return response.data;
  }, []);
  
  const getAgentLogs = useCallback(async (agentId: string, limit = 100) => {
    const response = await axios.get(`/api/v1/agent/${agentId}/logs`, {
      params: { limit }
    });
    return response.data;
  }, []);
  
  return {
    submitPrompt,
    getWorkflowStatus,
    getAgentLogs,
    loading,
    error
  };
};
```

## ğŸ¯ Phase 2: í•µì‹¬ ì„±ëŠ¥ ìµœì í™” (2-4ì£¼)

### 2.1 ì ì‘í˜• RAG ì‹œìŠ¤í…œ
**ìš°ì„ ìˆœìœ„**: ğŸ”´ Critical  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 1ì£¼

#### êµ¬í˜„ ë‚´ìš©
```python
# src/project_maestro/core/adaptive_rag.py
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

class AdaptiveRAGSystem:
    """ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜ ì ì‘í˜• RAG"""
    
    def __init__(self):
        self.feedback_history = []
        self.retrieval_strategies = {
            'semantic': SemanticRetriever(),
            'keyword': KeywordRetriever(),
            'hybrid': HybridRetriever(),
            'rerank': RerankRetriever()
        }
        self.strategy_weights = {k: 0.25 for k in self.retrieval_strategies}
    
    async def adaptive_retrieve(
        self, 
        query: str, 
        user_context: Dict
    ) -> List[Document]:
        """ì ì‘í˜• ê²€ìƒ‰ ì „ëµ"""
        
        # ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì „ëµ ì„ íƒ
        best_strategy = self._select_strategy(user_context)
        
        # ë‹¤ì¤‘ ì „ëµ ì•™ìƒë¸”
        results = {}
        for name, retriever in self.retrieval_strategies.items():
            weight = self.strategy_weights[name]
            if weight > 0.1:  # ì„ê³„ê°’ ì´ìƒë§Œ ì‚¬ìš©
                docs = await retriever.retrieve(query)
                results[name] = (docs, weight)
        
        # ê°€ì¤‘ í•©ì‚° ë° ì¬ìˆœìœ„
        final_docs = self._weighted_merge(results)
        
        # ë™ì  ì²­í‚¹ ì ìš©
        optimized_docs = await self._dynamic_chunking(final_docs, query)
        
        return optimized_docs
    
    async def _dynamic_chunking(
        self, 
        docs: List[Document], 
        query: str
    ) -> List[Document]:
        """ì¿¼ë¦¬ ê¸°ë°˜ ë™ì  ì²­í‚¹"""
        
        # ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„
        complexity = self._analyze_query_complexity(query)
        
        # ë³µì¡ë„ì— ë”°ë¥¸ ì²­í¬ í¬ê¸° ì¡°ì •
        if complexity > 0.7:
            chunk_size = 1500  # ë” ë§ì€ ì»¨í…ìŠ¤íŠ¸
            overlap = 300
        elif complexity > 0.4:
            chunk_size = 1000
            overlap = 200
        else:
            chunk_size = 500
            overlap = 100
        
        # ì¬ì²­í‚¹
        rechunked_docs = []
        for doc in docs:
            chunks = self._rechunk_document(
                doc, 
                chunk_size, 
                overlap
            )
            rechunked_docs.extend(chunks)
        
        return rechunked_docs
    
    def update_strategy_weights(
        self, 
        feedback: Dict
    ):
        """í”¼ë“œë°± ê¸°ë°˜ ì „ëµ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸"""
        strategy_used = feedback['strategy']
        satisfaction = feedback['satisfaction']
        
        # ì§€ìˆ˜ ì´ë™ í‰ê· ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        alpha = 0.1
        for strategy in self.strategy_weights:
            if strategy == strategy_used:
                delta = satisfaction - 0.5
            else:
                delta = -0.01
            
            self.strategy_weights[strategy] = (
                (1 - alpha) * self.strategy_weights[strategy] + 
                alpha * delta
            )
        
        # ì •ê·œí™”
        total = sum(self.strategy_weights.values())
        self.strategy_weights = {
            k: v/total for k, v in self.strategy_weights.items()
        }
```

### 2.2 ì¸í…”ë¦¬ì „íŠ¸ ìºì‹± ì‹œìŠ¤í…œ
**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ Important  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 3ì¼

#### êµ¬í˜„ ë‚´ìš©
```python
# src/project_maestro/core/intelligent_cache.py
from typing import Optional, Any
import hashlib
import pickle

class IntelligentCacheSystem:
    """ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ ê¸°ë°˜ ì¸í…”ë¦¬ì „íŠ¸ ìºì‹±"""
    
    def __init__(self):
        self.semantic_cache = {}
        self.embeddings_cache = {}
        self.ttl_manager = TTLManager()
        
    async def semantic_lookup(
        self, 
        query: str, 
        threshold: float = 0.85
    ) -> Optional[Any]:
        """ì˜ë¯¸ë¡ ì  ìºì‹œ ê²€ìƒ‰"""
        
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = await self._get_embedding(query)
        
        # ìœ ì‚¬ë„ ê²€ìƒ‰
        best_match = None
        best_score = 0
        
        for cached_query, cached_data in self.semantic_cache.items():
            cached_embedding = self.embeddings_cache[cached_query]
            similarity = cosine_similarity(
                [query_embedding], 
                [cached_embedding]
            )[0][0]
            
            if similarity > threshold and similarity > best_score:
                best_match = cached_data
                best_score = similarity
        
        if best_match:
            # ìºì‹œ íˆíŠ¸ í†µê³„ ì—…ë°ì´íŠ¸
            self._update_hit_statistics(best_score)
            return best_match
        
        return None
    
    async def intelligent_store(
        self, 
        query: str, 
        response: Any,
        metadata: Dict = None
    ):
        """ì§€ëŠ¥ì  ìºì‹œ ì €ì¥"""
        
        # ì‘ë‹µ í’ˆì§ˆ í‰ê°€
        quality_score = await self._evaluate_response_quality(
            query, 
            response
        )
        
        # í’ˆì§ˆì´ ë†’ì€ ì‘ë‹µë§Œ ìºì‹±
        if quality_score > 0.7:
            embedding = await self._get_embedding(query)
            
            # ì ì‘í˜• TTL ì„¤ì •
            ttl = self._calculate_adaptive_ttl(
                quality_score,
                metadata
            )
            
            self.semantic_cache[query] = {
                'response': response,
                'quality': quality_score,
                'metadata': metadata,
                'timestamp': time.time()
            }
            self.embeddings_cache[query] = embedding
            self.ttl_manager.set_ttl(query, ttl)
    
    def _calculate_adaptive_ttl(
        self, 
        quality_score: float,
        metadata: Dict
    ) -> int:
        """í’ˆì§ˆê³¼ ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ì ì‘í˜• TTL"""
        
        base_ttl = 3600  # 1ì‹œê°„ ê¸°ë³¸
        
        # í’ˆì§ˆ ê¸°ë°˜ ì¡°ì •
        quality_multiplier = quality_score * 2
        
        # ì»¨í…ì¸  íƒ€ì… ê¸°ë°˜ ì¡°ì •
        if metadata and metadata.get('content_type') == 'static':
            type_multiplier = 3
        elif metadata and metadata.get('content_type') == 'dynamic':
            type_multiplier = 0.5
        else:
            type_multiplier = 1
        
        # ì‚¬ìš© ë¹ˆë„ ê¸°ë°˜ ì¡°ì •
        usage_multiplier = metadata.get('usage_frequency', 1.0)
        
        return int(base_ttl * quality_multiplier * type_multiplier * usage_multiplier)
```

### 2.3 ì—ì´ì „íŠ¸ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ Important  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 4ì¼

#### êµ¬í˜„ ë‚´ìš©
```python
# src/project_maestro/core/agent_profiler.py
import cProfile
import pstats
from memory_profiler import profile
import tracemalloc

class AgentPerformanceProfiler:
    """ì—ì´ì „íŠ¸ ì„±ëŠ¥ ìƒì„¸ í”„ë¡œíŒŒì¼ë§"""
    
    def __init__(self):
        self.performance_history = defaultdict(list)
        self.resource_usage = defaultdict(dict)
        
    async def profile_agent_execution(
        self,
        agent: Agent,
        task: Dict
    ) -> Dict:
        """ì—ì´ì „íŠ¸ ì‹¤í–‰ í”„ë¡œíŒŒì¼ë§"""
        
        # CPU í”„ë¡œíŒŒì¼ë§
        cpu_profiler = cProfile.Profile()
        
        # ë©”ëª¨ë¦¬ ì¶”ì  ì‹œì‘
        tracemalloc.start()
        memory_before = tracemalloc.get_traced_memory()
        
        # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
        start_time = time.perf_counter()
        
        # ì—ì´ì „íŠ¸ ì‹¤í–‰
        cpu_profiler.enable()
        try:
            result = await agent.execute(task)
        finally:
            cpu_profiler.disable()
        
        end_time = time.perf_counter()
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°
        memory_after = tracemalloc.get_traced_memory()
        memory_usage = memory_after[0] - memory_before[0]
        
        # í”„ë¡œíŒŒì¼ë§ ê²°ê³¼ ë¶„ì„
        stats = pstats.Stats(cpu_profiler)
        top_functions = self._extract_top_functions(stats)
        
        profile_result = {
            'agent': agent.name,
            'task_id': task.get('id'),
            'execution_time': end_time - start_time,
            'memory_usage_mb': memory_usage / 1024 / 1024,
            'cpu_top_functions': top_functions,
            'token_usage': await self._calculate_token_usage(agent, task, result),
            'api_calls': agent.api_call_count,
            'cache_hits': agent.cache_hit_count
        }
        
        # ì„±ëŠ¥ ì´ìƒ ê°ì§€
        anomalies = self._detect_performance_anomalies(profile_result)
        if anomalies:
            await self._handle_performance_anomalies(anomalies)
        
        # ê¸°ë¡ ì €ì¥
        self.performance_history[agent.name].append(profile_result)
        
        return profile_result
    
    def _detect_performance_anomalies(
        self, 
        profile: Dict
    ) -> List[Dict]:
        """ì„±ëŠ¥ ì´ìƒ ê°ì§€"""
        anomalies = []
        
        # ì‹¤í–‰ ì‹œê°„ ì´ìƒ
        if profile['execution_time'] > 10:  # 10ì´ˆ ì´ìƒ
            anomalies.append({
                'type': 'slow_execution',
                'severity': 'high',
                'value': profile['execution_time']
            })
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš© ì´ìƒ
        if profile['memory_usage_mb'] > 500:  # 500MB ì´ìƒ
            anomalies.append({
                'type': 'high_memory',
                'severity': 'medium',
                'value': profile['memory_usage_mb']
            })
        
        # í† í° ì‚¬ìš© ì´ìƒ
        if profile['token_usage'] > 10000:  # 10K í† í° ì´ìƒ
            anomalies.append({
                'type': 'excessive_tokens',
                'severity': 'medium',
                'value': profile['token_usage']
            })
        
        return anomalies
    
    async def generate_optimization_recommendations(
        self,
        agent_name: str
    ) -> List[Dict]:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        
        history = self.performance_history[agent_name]
        if len(history) < 10:
            return []
        
        recommendations = []
        
        # í‰ê·  ì„±ëŠ¥ ê³„ì‚°
        avg_time = np.mean([h['execution_time'] for h in history])
        avg_memory = np.mean([h['memory_usage_mb'] for h in history])
        avg_tokens = np.mean([h['token_usage'] for h in history])
        
        # ì‹œê°„ ìµœì í™” ê¶Œì¥
        if avg_time > 5:
            recommendations.append({
                'type': 'execution_time',
                'current': avg_time,
                'target': 2,
                'suggestion': 'Consider implementing result caching or parallel processing'
            })
        
        # ë©”ëª¨ë¦¬ ìµœì í™” ê¶Œì¥
        if avg_memory > 200:
            recommendations.append({
                'type': 'memory_usage',
                'current': avg_memory,
                'target': 100,
                'suggestion': 'Implement streaming responses and reduce context size'
            })
        
        # í† í° ìµœì í™” ê¶Œì¥
        if avg_tokens > 5000:
            recommendations.append({
                'type': 'token_usage',
                'current': avg_tokens,
                'target': 2000,
                'suggestion': 'Use summary memory and dynamic context pruning'
            })
        
        return recommendations
```

---

## ğŸ”¬ Phase 3: ê³ ê¸‰ ê¸°ëŠ¥ êµ¬í˜„ (1-2ê°œì›”)

### 3.0 í”„ë¡ íŠ¸ì—”ë“œ ê³ ê¸‰ ì‹œê°í™” ë° ì¸í„°ë™ì…˜
**ìš°ì„ ìˆœìœ„**: ğŸŸ¡ Important  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 1ì£¼

#### êµ¬í˜„ ë‚´ìš©
```typescript
// frontend/src/components/visualization/AgentFlowDiagram.tsx
import React, { useEffect, useRef } from 'react';
import * as d3 from 'd3';
import { sankey, sankeyLinkHorizontal } from 'd3-sankey';

export const AgentFlowDiagram: React.FC<{
  workflowData: WorkflowData;
  interactive?: boolean;
}> = ({ workflowData, interactive = true }) => {
  const svgRef = useRef<SVGSVGElement>(null);
  
  useEffect(() => {
    if (!svgRef.current || !workflowData) return;
    
    const svg = d3.select(svgRef.current);
    const width = 1200;
    const height = 600;
    const margin = { top: 20, right: 200, bottom: 20, left: 20 };
    
    // Sankey ë‹¤ì´ì–´ê·¸ë¨ ì„¤ì •
    const sankeyGenerator = sankey()
      .nodeWidth(36)
      .nodePadding(10)
      .extent([[margin.left, margin.top], [width - margin.right, height - margin.bottom]]);
    
    // ë°ì´í„° ë³€í™˜
    const nodes = workflowData.agents.map(agent => ({
      id: agent.id,
      name: agent.name,
      type: agent.type,
      status: agent.status,
      metrics: agent.metrics
    }));
    
    const links = workflowData.connections.map(conn => ({
      source: conn.from,
      target: conn.to,
      value: conn.dataFlow || 1,
      type: conn.type
    }));
    
    const graph = { nodes, links };
    sankeyGenerator(graph);
    
    // ë§í¬ ë Œë”ë§
    const link = svg.append('g')
      .selectAll('.link')
      .data(graph.links)
      .enter().append('path')
      .attr('class', 'link')
      .attr('d', sankeyLinkHorizontal())
      .style('stroke', d => getLinkColor(d.type))
      .style('stroke-width', d => Math.max(1, d.width))
      .style('fill', 'none')
      .style('opacity', 0.5);
    
    // ë…¸ë“œ ë Œë”ë§
    const node = svg.append('g')
      .selectAll('.node')
      .data(graph.nodes)
      .enter().append('g')
      .attr('class', 'node')
      .attr('transform', d => `translate(${d.x0}, ${d.y0})`);
    
    // ë…¸ë“œ ì‚¬ê°í˜•
    node.append('rect')
      .attr('height', d => d.y1 - d.y0)
      .attr('width', sankeyGenerator.nodeWidth())
      .style('fill', d => getNodeColor(d.status))
      .style('stroke', '#000')
      .style('cursor', interactive ? 'pointer' : 'default');
    
    // ë…¸ë“œ ë ˆì´ë¸”
    node.append('text')
      .attr('x', -6)
      .attr('y', d => (d.y1 - d.y0) / 2)
      .attr('dy', '0.35em')
      .attr('text-anchor', 'end')
      .text(d => d.name)
      .style('font-size', '12px')
      .style('fill', '#fff');
    
    // ì¸í„°ë™í‹°ë¸Œ ê¸°ëŠ¥
    if (interactive) {
      // í˜¸ë²„ íš¨ê³¼
      node.on('mouseover', function(event, d) {
        // íˆ´íŒ í‘œì‹œ
        showTooltip(event, d);
        
        // ì—°ê²°ëœ ë§í¬ í•˜ì´ë¼ì´íŠ¸
        link.style('opacity', l => 
          l.source === d || l.target === d ? 0.9 : 0.2
        );
      })
      .on('mouseout', function() {
        hideTooltip();
        link.style('opacity', 0.5);
      })
      .on('click', function(event, d) {
        // ì—ì´ì „íŠ¸ ìƒì„¸ ì •ë³´ íŒ¨ë„ ì—´ê¸°
        openAgentDetails(d);
      });
    }
    
    // ì‹¤ì‹œê°„ ì• ë‹ˆë©”ì´ì…˜
    const animateFlow = () => {
      link.style('stroke-dasharray', '5, 5')
        .style('stroke-dashoffset', 0)
        .transition()
        .duration(2000)
        .ease(d3.easeLinear)
        .style('stroke-dashoffset', -10)
        .on('end', animateFlow);
    };
    
    if (workflowData.status === 'running') {
      animateFlow();
    }
    
  }, [workflowData, interactive]);
  
  const getNodeColor = (status: string) => {
    const colors = {
      idle: '#525252',
      planning: '#0f62fe',
      executing: '#42be65',
      complete: '#24a148',
      error: '#da1e28',
      waiting: '#f1c21b'
    };
    return colors[status] || '#525252';
  };
  
  const getLinkColor = (type: string) => {
    const colors = {
      data: '#0f62fe',
      control: '#8a3ffc',
      feedback: '#f1c21b'
    };
    return colors[type] || '#393939';
  };
  
  return (
    <div className="agent-flow-diagram">
      <svg ref={svgRef} width={1200} height={600} />
      <AgentDetailsPanel />
      <MetricsOverlay />
    </div>
  );
};

// frontend/src/components/visualization/MetricsDashboard.tsx
import React from 'react';
import { 
  AreaChart, 
  Area, 
  LineChart, 
  Line, 
  BarChart, 
  Bar, 
  PieChart, 
  Pie,
  XAxis, 
  YAxis, 
  CartesianGrid, 
  Tooltip, 
  Legend,
  ResponsiveContainer
} from 'recharts';
import { Tile, Tab, Tabs, TabList, TabPanels, TabPanel } from '@carbon/react';

export const MetricsDashboard: React.FC<{
  metrics: WorkflowMetrics;
}> = ({ metrics }) => {
  return (
    <div className="metrics-dashboard">
      <Tabs>
        <TabList aria-label="Metrics tabs">
          <Tab>Performance</Tab>
          <Tab>Token Usage</Tab>
          <Tab>Agent Efficiency</Tab>
          <Tab>Cost Analysis</Tab>
        </TabList>
        
        <TabPanels>
          <TabPanel>
            <div className="performance-metrics">
              <Tile className="metric-tile">
                <h4>Response Time Trend</h4>
                <ResponsiveContainer width="100%" height={300}>
                  <AreaChart data={metrics.responseTimeTrend}>
                    <CartesianGrid strokeDasharray="3 3" />
                    <XAxis dataKey="time" />
                    <YAxis />
                    <Tooltip />
                    <Area 
                      type="monotone" 
                      dataKey="value" 
                      stroke="#0f62fe" 
                      fill="#0f62fe" 
                      fillOpacity={0.3}
                    />
                  </AreaChart>
                </ResponsiveContainer>
              </Tile>
              
              <Tile className="metric-tile">
                <h4>Throughput</h4>
                <ResponsiveContainer width="100%" height={300}>
                  <LineChart data={metrics.throughput}>
                    <CartesianGrid strokeDasharray="3 3" />
                    <XAxis dataKey="time" />
                    <YAxis />
                    <Tooltip />
                    <Legend />
                    <Line 
                      type="monotone" 
                      dataKey="requests" 
                      stroke="#42be65" 
                      strokeWidth={2}
                    />
                  </LineChart>
                </ResponsiveContainer>
              </Tile>
            </div>
          </TabPanel>
          
          <TabPanel>
            <div className="token-metrics">
              <Tile className="metric-tile">
                <h4>Token Usage by Agent</h4>
                <ResponsiveContainer width="100%" height={300}>
                  <BarChart data={metrics.tokensByAgent}>
                    <CartesianGrid strokeDasharray="3 3" />
                    <XAxis dataKey="agent" />
                    <YAxis />
                    <Tooltip />
                    <Bar dataKey="tokens" fill="#8a3ffc" />
                  </BarChart>
                </ResponsiveContainer>
              </Tile>
              
              <Tile className="metric-tile">
                <h4>Token Distribution</h4>
                <ResponsiveContainer width="100%" height={300}>
                  <PieChart>
                    <Pie
                      data={metrics.tokenDistribution}
                      dataKey="value"
                      nameKey="category"
                      cx="50%"
                      cy="50%"
                      outerRadius={100}
                      fill="#0f62fe"
                      label
                    />
                    <Tooltip />
                  </PieChart>
                </ResponsiveContainer>
              </Tile>
            </div>
          </TabPanel>
          
          <TabPanel>
            <AgentEfficiencyMatrix agents={metrics.agents} />
          </TabPanel>
          
          <TabPanel>
            <CostBreakdown costs={metrics.costs} />
          </TabPanel>
        </TabPanels>
      </Tabs>
    </div>
  );
};

// frontend/src/components/visualization/AgentHeatmap.tsx
import React, { useEffect, useRef } from 'react';
import * as d3 from 'd3';

export const AgentHeatmap: React.FC<{
  data: AgentPerformanceData[];
}> = ({ data }) => {
  const svgRef = useRef<SVGSVGElement>(null);
  
  useEffect(() => {
    if (!svgRef.current || !data) return;
    
    const margin = { top: 50, right: 50, bottom: 100, left: 100 };
    const width = 800 - margin.left - margin.right;
    const height = 400 - margin.top - margin.bottom;
    
    const svg = d3.select(svgRef.current);
    
    // ì¶• ì„¤ì •
    const agents = [...new Set(data.map(d => d.agent))];
    const metrics = [...new Set(data.map(d => d.metric))];
    
    const x = d3.scaleBand()
      .range([0, width])
      .domain(agents)
      .padding(0.01);
    
    const y = d3.scaleBand()
      .range([height, 0])
      .domain(metrics)
      .padding(0.01);
    
    // ìƒ‰ìƒ ìŠ¤ì¼€ì¼
    const colorScale = d3.scaleSequential()
      .interpolator(d3.interpolateRdYlGn)
      .domain([0, 100]);
    
    // íˆíŠ¸ë§µ ê·¸ë¦¬ê¸°
    svg.append('g')
      .selectAll()
      .data(data)
      .enter()
      .append('rect')
      .attr('x', d => x(d.agent))
      .attr('y', d => y(d.metric))
      .attr('width', x.bandwidth())
      .attr('height', y.bandwidth())
      .style('fill', d => colorScale(d.value))
      .style('stroke', 'white')
      .style('stroke-width', 2)
      .on('mouseover', function(event, d) {
        // íˆ´íŒ í‘œì‹œ
        d3.select(this)
          .style('stroke', 'black')
          .style('opacity', 0.8);
        
        showTooltip(event, {
          agent: d.agent,
          metric: d.metric,
          value: d.value,
          benchmark: d.benchmark
        });
      })
      .on('mouseout', function() {
        d3.select(this)
          .style('stroke', 'white')
          .style('opacity', 1);
        hideTooltip();
      });
    
    // Xì¶•
    svg.append('g')
      .attr('transform', `translate(0, ${height})`)
      .call(d3.axisBottom(x))
      .selectAll('text')
      .style('text-anchor', 'end')
      .attr('dx', '-.8em')
      .attr('dy', '.15em')
      .attr('transform', 'rotate(-45)');
    
    // Yì¶•
    svg.append('g')
      .call(d3.axisLeft(y));
    
    // ë²”ë¡€
    const legend = svg.append('g')
      .attr('transform', `translate(${width + 20}, 0)`);
    
    const legendScale = d3.scaleLinear()
      .domain([0, 100])
      .range([height, 0]);
    
    const legendAxis = d3.axisRight(legendScale)
      .ticks(5)
      .tickFormat(d => `${d}%`);
    
    legend.append('g')
      .call(legendAxis);
    
    // ê·¸ë¼ë°ì´ì…˜ ë²”ë¡€
    const gradient = svg.append('defs')
      .append('linearGradient')
      .attr('id', 'gradient')
      .attr('x1', '0%')
      .attr('x2', '0%')
      .attr('y1', '100%')
      .attr('y2', '0%');
    
    gradient.selectAll('stop')
      .data(d3.range(0, 1.01, 0.01))
      .enter()
      .append('stop')
      .attr('offset', d => `${d * 100}%`)
      .attr('stop-color', d => colorScale(d * 100));
    
    legend.append('rect')
      .attr('width', 20)
      .attr('height', height)
      .style('fill', 'url(#gradient)');
    
  }, [data]);
  
  return (
    <div className="agent-heatmap">
      <h3>Agent Performance Heatmap</h3>
      <svg ref={svgRef} width={900} height={500} />
    </div>
  );
};
```

### 3.1 ììœ¨ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
**ìš°ì„ ìˆœìœ„**: ğŸŸ¢ Recommended  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 2ì£¼

#### êµ¬í˜„ ë‚´ìš©
```python
# src/project_maestro/core/autonomous_agents.py
from typing import List, Dict, Any
import asyncio

class AutonomousAgentSystem:
    """ììœ¨ì  ì˜ì‚¬ê²°ì •ì´ ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.goal_manager = GoalManager()
        self.planning_engine = PlanningEngine()
        self.execution_monitor = ExecutionMonitor()
        
    async def autonomous_execution(
        self,
        high_level_goal: str
    ) -> Dict:
        """ê³ ìˆ˜ì¤€ ëª©í‘œë¥¼ ììœ¨ì ìœ¼ë¡œ ë‹¬ì„±"""
        
        # ëª©í‘œ ë¶„í•´
        sub_goals = await self.goal_manager.decompose_goal(high_level_goal)
        
        # ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
        execution_plan = await self.planning_engine.create_plan(sub_goals)
        
        # ììœ¨ ì‹¤í–‰ ë£¨í”„
        results = []
        for step in execution_plan:
            # í˜„ì¬ ìƒíƒœ í‰ê°€
            current_state = await self._evaluate_state()
            
            # ê³„íš ì¡°ì • í•„ìš” ì—¬ë¶€ íŒë‹¨
            if await self._needs_replanning(current_state, step):
                execution_plan = await self.planning_engine.replan(
                    current_state,
                    execution_plan
                )
            
            # ë‹¨ê³„ ì‹¤í–‰
            result = await self._execute_step(step)
            results.append(result)
            
            # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
            await self.execution_monitor.track_progress(step, result)
            
            # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ í™•ì¸
            if await self.goal_manager.is_goal_achieved(high_level_goal):
                break
        
        return {
            'goal': high_level_goal,
            'plan': execution_plan,
            'results': results,
            'success': await self.goal_manager.is_goal_achieved(high_level_goal)
        }
    
    async def _execute_step(self, step: Dict) -> Dict:
        """ë‹¨ê³„ë³„ ììœ¨ ì‹¤í–‰"""
        
        # ìµœì  ì—ì´ì „íŠ¸ ì„ íƒ
        best_agent = await self._select_best_agent(step)
        
        # ììœ¨ì  íŒŒë¼ë¯¸í„° ì¡°ì •
        optimized_params = await self._optimize_parameters(step, best_agent)
        
        # ì‹¤í–‰ ë° ìê°€ ê²€ì¦
        result = await best_agent.execute(step, optimized_params)
        
        # ê²°ê³¼ í’ˆì§ˆ í‰ê°€
        quality = await self._evaluate_result_quality(result)
        
        # í’ˆì§ˆì´ ë‚®ìœ¼ë©´ ì¬ì‹œë„ ë˜ëŠ” ëŒ€ì•ˆ ì‹¤í–‰
        if quality < 0.7:
            result = await self._handle_low_quality_result(step, result)
        
        return result
```

### 3.2 ì—°í•© í•™ìŠµ ê¸°ë°˜ ê°œì„ 
**ìš°ì„ ìˆœìœ„**: ğŸŸ¢ Recommended  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 2ì£¼

#### êµ¬í˜„ ë‚´ìš©
```python
# src/project_maestro/core/federated_learning.py
import torch
import torch.nn as nn
from typing import List, Dict

class FederatedLearningSystem:
    """ì—°í•© í•™ìŠµ ê¸°ë°˜ ì—ì´ì „íŠ¸ ê°œì„ """
    
    def __init__(self):
        self.local_models = {}
        self.global_model = self._initialize_global_model()
        self.aggregator = FederatedAggregator()
        
    async def federated_training_round(
        self,
        participating_agents: List[Agent]
    ) -> Dict:
        """ì—°í•© í•™ìŠµ ë¼ìš´ë“œ ì‹¤í–‰"""
        
        local_updates = []
        
        # ê° ì—ì´ì „íŠ¸ì˜ ë¡œì»¬ í•™ìŠµ
        for agent in participating_agents:
            # ë¡œì»¬ ë°ì´í„°ë¡œ í•™ìŠµ
            local_model = await self._train_local_model(
                agent,
                self.global_model.state_dict()
            )
            
            # ì°¨ë“± í”„ë¼ì´ë²„ì‹œ ì ìš©
            private_update = self._apply_differential_privacy(
                local_model,
                epsilon=1.0
            )
            
            local_updates.append({
                'agent_id': agent.id,
                'update': private_update,
                'data_size': agent.local_data_size
            })
        
        # ê°€ì¤‘ ì§‘ê³„
        aggregated_update = self.aggregator.aggregate(local_updates)
        
        # ê¸€ë¡œë²Œ ëª¨ë¸ ì—…ë°ì´íŠ¸
        self.global_model.load_state_dict(aggregated_update)
        
        # ì„±ëŠ¥ í‰ê°€
        performance = await self._evaluate_global_model()
        
        return {
            'round_complete': True,
            'participants': len(participating_agents),
            'performance_improvement': performance['improvement'],
            'global_accuracy': performance['accuracy']
        }
    
    def _apply_differential_privacy(
        self,
        model: nn.Module,
        epsilon: float
    ) -> Dict:
        """ì°¨ë“± í”„ë¼ì´ë²„ì‹œ ì ìš©"""
        
        noisy_state_dict = {}
        
        for key, param in model.state_dict().items():
            # ë¼í”Œë¼ìŠ¤ ë…¸ì´ì¦ˆ ì¶”ê°€
            sensitivity = self._calculate_sensitivity(param)
            noise_scale = sensitivity / epsilon
            noise = torch.distributions.Laplace(0, noise_scale).sample(param.shape)
            
            noisy_state_dict[key] = param + noise
        
        return noisy_state_dict
```

### 3.3 ì‹¤ì‹œê°„ A/B í…ŒìŠ¤íŒ… ì‹œìŠ¤í…œ
**ìš°ì„ ìˆœìœ„**: ğŸŸ¢ Recommended  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 1ì£¼

#### êµ¬í˜„ ë‚´ìš©
```python
# src/project_maestro/core/ab_testing.py
from scipy import stats
import numpy as np

class RealtimeABTestingSystem:
    """ì‹¤ì‹œê°„ A/B í…ŒìŠ¤íŒ… ë° ìµœì í™”"""
    
    def __init__(self):
        self.experiments = {}
        self.results_tracker = ResultsTracker()
        self.statistical_analyzer = StatisticalAnalyzer()
        
    async def create_experiment(
        self,
        name: str,
        variants: Dict[str, Any],
        success_metrics: List[str]
    ) -> str:
        """A/B í…ŒìŠ¤íŠ¸ ì‹¤í—˜ ìƒì„±"""
        
        experiment_id = str(uuid.uuid4())
        
        self.experiments[experiment_id] = {
            'name': name,
            'variants': variants,
            'metrics': success_metrics,
            'allocation': self._calculate_initial_allocation(len(variants)),
            'start_time': datetime.now(),
            'status': 'running'
        }
        
        return experiment_id
    
    async def route_request(
        self,
        experiment_id: str,
        user_context: Dict
    ) -> str:
        """ìš”ì²­ì„ ì‹¤í—˜ ë³€í˜•ìœ¼ë¡œ ë¼ìš°íŒ…"""
        
        experiment = self.experiments[experiment_id]
        
        # Multi-Armed Bandit ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
        variant = await self._select_variant_mab(
            experiment,
            user_context
        )
        
        # í• ë‹¹ ê¸°ë¡
        await self.results_tracker.record_assignment(
            experiment_id,
            user_context['user_id'],
            variant
        )
        
        return variant
    
    async def _select_variant_mab(
        self,
        experiment: Dict,
        user_context: Dict
    ) -> str:
        """Thompson Samplingì„ ì‚¬ìš©í•œ ë³€í˜• ì„ íƒ"""
        
        # ê° ë³€í˜•ì˜ ì„±ê³¼ í†µê³„
        variant_stats = await self.results_tracker.get_variant_stats(
            experiment['id']
        )
        
        # Thompson Sampling
        samples = {}
        for variant, stats in variant_stats.items():
            # Beta ë¶„í¬ì—ì„œ ìƒ˜í”Œë§
            alpha = stats['successes'] + 1
            beta = stats['failures'] + 1
            samples[variant] = np.random.beta(alpha, beta)
        
        # ìµœê³  ìƒ˜í”Œ ì„ íƒ
        return max(samples, key=samples.get)
    
    async def analyze_experiment(
        self,
        experiment_id: str
    ) -> Dict:
        """ì‹¤í—˜ ê²°ê³¼ í†µê³„ ë¶„ì„"""
        
        data = await self.results_tracker.get_experiment_data(experiment_id)
        
        analysis = {
            'sample_size': len(data),
            'variants': {}
        }
        
        # ê° ë³€í˜•ë³„ ë¶„ì„
        for variant in self.experiments[experiment_id]['variants']:
            variant_data = data[data['variant'] == variant]
            
            analysis['variants'][variant] = {
                'conversion_rate': variant_data['converted'].mean(),
                'confidence_interval': self._calculate_confidence_interval(
                    variant_data['converted']
                ),
                'sample_size': len(variant_data)
            }
        
        # í†µê³„ì  ìœ ì˜ì„± í…ŒìŠ¤íŠ¸
        if len(analysis['variants']) == 2:
            variants = list(analysis['variants'].keys())
            a_data = data[data['variant'] == variants[0]]['converted']
            b_data = data[data['variant'] == variants[1]]['converted']
            
            # Chi-squared test
            chi2, p_value = stats.chi2_contingency([
                [a_data.sum(), len(a_data) - a_data.sum()],
                [b_data.sum(), len(b_data) - b_data.sum()]
            ])[:2]
            
            analysis['statistical_significance'] = {
                'p_value': p_value,
                'is_significant': p_value < 0.05,
                'chi2_statistic': chi2
            }
        
        # ìŠ¹ì ê²°ì •
        best_variant = max(
            analysis['variants'].items(),
            key=lambda x: x[1]['conversion_rate']
        )[0]
        
        analysis['recommendation'] = {
            'winner': best_variant,
            'confidence': self._calculate_win_probability(data, best_variant)
        }
        
        return analysis
```

---

## ğŸš¨ Phase 4: í”„ë¡œë•ì…˜ ì¤€ë¹„ (2-3ì£¼)

### 4.1 ë¶„ì‚° ì²˜ë¦¬ ì‹œìŠ¤í…œ
**ìš°ì„ ìˆœìœ„**: ğŸ”´ Critical  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 1ì£¼

#### êµ¬í˜„ ë‚´ìš©
```python
# src/project_maestro/core/distributed_processing.py
from celery import Celery
from kombu import Queue
import ray

class DistributedProcessingSystem:
    """ë¶„ì‚° ì²˜ë¦¬ ë° ìŠ¤ì¼€ì¼ë§"""
    
    def __init__(self):
        # Celery ì„¤ì •
        self.celery_app = Celery(
            'maestro',
            broker='redis://localhost:6379/0',
            backend='redis://localhost:6379/1'
        )
        
        # Ray ì´ˆê¸°í™”
        ray.init(address='ray://localhost:10001')
        
        # í ì„¤ì •
        self.queues = {
            'high_priority': Queue('high', routing_key='high.*'),
            'default': Queue('default', routing_key='default.*'),
            'batch': Queue('batch', routing_key='batch.*')
        }
    
    @ray.remote
    class DistributedAgent:
        """Rayë¥¼ ì‚¬ìš©í•œ ë¶„ì‚° ì—ì´ì „íŠ¸"""
        
        def __init__(self, agent_config: Dict):
            self.agent = self._initialize_agent(agent_config)
            
        async def execute(self, task: Dict) -> Dict:
            """ë¶„ì‚° ì‹¤í–‰"""
            return await self.agent.execute(task)
    
    async def distribute_workflow(
        self,
        workflow: Dict,
        parallelism: int = 10
    ) -> List[Dict]:
        """ì›Œí¬í”Œë¡œìš° ë¶„ì‚° ì‹¤í–‰"""
        
        # ì‘ì—… ë¶„í• 
        task_batches = self._partition_tasks(
            workflow['tasks'],
            parallelism
        )
        
        # Ray actors ìƒì„±
        actors = [
            DistributedAgent.remote(self.agent_config)
            for _ in range(parallelism)
        ]
        
        # ë³‘ë ¬ ì‹¤í–‰
        futures = []
        for i, batch in enumerate(task_batches):
            actor = actors[i % len(actors)]
            for task in batch:
                future = actor.execute.remote(task)
                futures.append(future)
        
        # ê²°ê³¼ ìˆ˜ì§‘
        results = await ray.get(futures)
        
        return results
    
    @celery_app.task(bind=True, max_retries=3)
    def process_async_task(self, task_data: Dict) -> Dict:
        """ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬"""
        try:
            # ì‘ì—… ì²˜ë¦¬
            result = self._process_task(task_data)
            
            # ê²°ê³¼ ìºì‹±
            self._cache_result(task_data['id'], result)
            
            return result
            
        except Exception as exc:
            # ì¬ì‹œë„ ë¡œì§
            raise self.retry(exc=exc, countdown=60)
```

### 4.2 ì¥ì•  ë³µêµ¬ ì‹œìŠ¤í…œ
**ìš°ì„ ìˆœìœ„**: ğŸ”´ Critical  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 4ì¼

#### êµ¬í˜„ ë‚´ìš©
```python
# src/project_maestro/core/fault_tolerance.py
from circuit_breaker import CircuitBreaker
import tenacity

class FaultToleranceSystem:
    """ì¥ì•  ë³µêµ¬ ë° ë‚´ê²°í•¨ì„±"""
    
    def __init__(self):
        self.circuit_breakers = {}
        self.health_checker = HealthChecker()
        self.fallback_handlers = {}
        
    def create_circuit_breaker(
        self,
        service_name: str,
        failure_threshold: int = 5,
        recovery_timeout: int = 60
    ):
        """ì„œí‚· ë¸Œë ˆì´ì»¤ ìƒì„±"""
        
        self.circuit_breakers[service_name] = CircuitBreaker(
            failure_threshold=failure_threshold,
            recovery_timeout=recovery_timeout,
            expected_exception=Exception
        )
    
    @tenacity.retry(
        wait=tenacity.wait_exponential(multiplier=1, min=4, max=10),
        stop=tenacity.stop_after_attempt(3),
        retry=tenacity.retry_if_exception_type(Exception)
    )
    async def execute_with_retry(
        self,
        func: Callable,
        *args,
        **kwargs
    ) -> Any:
        """ì§€ìˆ˜ ë°±ì˜¤í”„ë¥¼ ì‚¬ìš©í•œ ì¬ì‹œë„"""
        
        try:
            return await func(*args, **kwargs)
        except Exception as e:
            # ì—ëŸ¬ ë¡œê¹…
            self.logger.error(f"Execution failed: {e}")
            raise
    
    async def execute_with_fallback(
        self,
        primary_func: Callable,
        fallback_func: Callable,
        *args,
        **kwargs
    ) -> Any:
        """í´ë°± ë©”ì»¤ë‹ˆì¦˜ì„ í¬í•¨í•œ ì‹¤í–‰"""
        
        try:
            # ì„œí‚· ë¸Œë ˆì´ì»¤ ì²´í¬
            service_name = primary_func.__name__
            
            if service_name in self.circuit_breakers:
                breaker = self.circuit_breakers[service_name]
                
                if breaker.current_state == 'open':
                    # ì„œí‚·ì´ ì—´ë ¤ìˆìœ¼ë©´ ì¦‰ì‹œ í´ë°±
                    return await fallback_func(*args, **kwargs)
            
            # ê¸°ë³¸ í•¨ìˆ˜ ì‹¤í–‰
            result = await primary_func(*args, **kwargs)
            
            # ì„±ê³µì‹œ ì„œí‚· ë¸Œë ˆì´ì»¤ ë¦¬ì…‹
            if service_name in self.circuit_breakers:
                self.circuit_breakers[service_name].call_succeeded()
            
            return result
            
        except Exception as e:
            # ì‹¤íŒ¨ ê¸°ë¡
            if service_name in self.circuit_breakers:
                self.circuit_breakers[service_name].call_failed()
            
            # í´ë°± ì‹¤í–‰
            self.logger.warning(f"Falling back due to: {e}")
            return await fallback_func(*args, **kwargs)
    
    async def health_check_loop(self):
        """ì§€ì†ì ì¸ ìƒíƒœ ì²´í¬"""
        
        while True:
            try:
                # ëª¨ë“  ì„œë¹„ìŠ¤ ìƒíƒœ ì²´í¬
                health_status = {}
                
                for service in self.monitored_services:
                    status = await self.health_checker.check(service)
                    health_status[service] = status
                    
                    # ë¹„ì •ìƒ ì„œë¹„ìŠ¤ ì²˜ë¦¬
                    if not status['healthy']:
                        await self._handle_unhealthy_service(service, status)
                
                # ìƒíƒœ ë³´ê³ 
                await self._report_health_status(health_status)
                
            except Exception as e:
                self.logger.error(f"Health check failed: {e}")
            
            await asyncio.sleep(30)  # 30ì´ˆë§ˆë‹¤ ì²´í¬
```

### 4.3 ë³´ì•ˆ ê°•í™”
**ìš°ì„ ìˆœìœ„**: ğŸ”´ Critical  
**ì˜ˆìƒ ì†Œìš”ì‹œê°„**: 1ì£¼

#### êµ¬í˜„ ë‚´ìš©
```python
# src/project_maestro/core/security_enhancement.py
from cryptography.fernet import Fernet
import jwt
from typing import Optional

class SecurityEnhancement:
    """ë³´ì•ˆ ê°•í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.encryption_key = Fernet.generate_key()
        self.cipher = Fernet(self.encryption_key)
        self.rate_limiter = RateLimiter()
        self.input_validator = InputValidator()
        
    async def secure_agent_communication(
        self,
        sender: str,
        receiver: str,
        message: Dict
    ) -> str:
        """ì—ì´ì „íŠ¸ ê°„ ë³´ì•ˆ í†µì‹ """
        
        # ë©”ì‹œì§€ ì„œëª…
        signed_message = self._sign_message(sender, message)
        
        # ì•”í˜¸í™”
        encrypted = self.cipher.encrypt(
            json.dumps(signed_message).encode()
        )
        
        # ì „ì†¡ ë¡œê·¸
        await self._log_communication(sender, receiver, encrypted)
        
        return encrypted
    
    def _sign_message(
        self,
        sender: str,
        message: Dict
    ) -> Dict:
        """JWTë¥¼ ì‚¬ìš©í•œ ë©”ì‹œì§€ ì„œëª…"""
        
        payload = {
            'sender': sender,
            'message': message,
            'timestamp': datetime.now().isoformat()
        }
        
        token = jwt.encode(
            payload,
            self.secret_key,
            algorithm='HS256'
        )
        
        return {
            'token': token,
            'sender': sender
        }
    
    async def validate_and_sanitize_input(
        self,
        input_data: Any,
        schema: Dict
    ) -> Tuple[bool, Any]:
        """ì…ë ¥ ê²€ì¦ ë° ì‚´ê· """
        
        # ìŠ¤í‚¤ë§ˆ ê²€ì¦
        is_valid = await self.input_validator.validate(input_data, schema)
        
        if not is_valid:
            return False, None
        
        # SQL ì¸ì ì…˜ ë°©ì§€
        sanitized = self._sanitize_sql_injection(input_data)
        
        # XSS ë°©ì§€
        sanitized = self._sanitize_xss(sanitized)
        
        # ëª…ë ¹ ì¸ì ì…˜ ë°©ì§€
        sanitized = self._sanitize_command_injection(sanitized)
        
        return True, sanitized
    
    async def apply_rate_limiting(
        self,
        user_id: str,
        endpoint: str
    ) -> bool:
        """ë ˆì´íŠ¸ ë¦¬ë¯¸íŒ… ì ìš©"""
        
        # ì‚¬ìš©ìë³„ ë ˆì´íŠ¸ ì²´í¬
        user_rate = await self.rate_limiter.check_user_rate(
            user_id,
            window=60,  # 1ë¶„
            max_requests=100
        )
        
        # ì—”ë“œí¬ì¸íŠ¸ë³„ ë ˆì´íŠ¸ ì²´í¬
        endpoint_rate = await self.rate_limiter.check_endpoint_rate(
            endpoint,
            window=60,
            max_requests=1000
        )
        
        # IP ê¸°ë°˜ ë ˆì´íŠ¸ ì²´í¬
        ip_rate = await self.rate_limiter.check_ip_rate(
            request.client.host,
            window=60,
            max_requests=500
        )
        
        return user_rate and endpoint_rate and ip_rate
    
    def encrypt_sensitive_data(
        self,
        data: Dict
    ) -> Dict:
        """ë¯¼ê°í•œ ë°ì´í„° ì•”í˜¸í™”"""
        
        sensitive_fields = [
            'api_key', 
            'password', 
            'token', 
            'secret',
            'private_key'
        ]
        
        encrypted_data = data.copy()
        
        for field in sensitive_fields:
            if field in encrypted_data:
                encrypted_data[field] = self.cipher.encrypt(
                    str(encrypted_data[field]).encode()
                ).decode()
        
        return encrypted_data
```

---

## ğŸ“ˆ ì„±ê³µ ì§€í‘œ ë° ëª¨ë‹ˆí„°ë§

### í•µì‹¬ ì„±ëŠ¥ ì§€í‘œ (KPIs)

| ì§€í‘œ | í˜„ì¬ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|-----|------|------|----------|
| í‰ê·  ì‘ë‹µ ì‹œê°„ | - | < 2ì´ˆ | Prometheus + Grafana |
| ì—ì´ì „íŠ¸ ì„±ê³µë¥  | - | > 95% | Custom metrics |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  | - | < 70% | System monitoring |
| API ê°€ìš©ì„± | - | > 99.9% | Uptime monitoring |
| í† í° íš¨ìœ¨ì„± | - | 30% ê°ì†Œ | Token tracking |
| ìºì‹œ íˆíŠ¸ìœ¨ | - | > 80% | Redis monitoring |

### ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì„±

```yaml
# monitoring/dashboard.yaml
dashboards:
  - name: Agent Performance
    panels:
      - execution_time_by_agent
      - success_rate_by_agent
      - token_usage_trends
      - memory_consumption
      
  - name: System Health
    panels:
      - api_response_times
      - error_rates
      - database_performance
      - queue_lengths
      
  - name: Business Metrics
    panels:
      - daily_active_users
      - project_completion_rate
      - user_satisfaction_score
      - cost_per_request
```

---

## ğŸ¯ ìš°ì„ ìˆœìœ„ ë§¤íŠ¸ë¦­ìŠ¤

### ê¸´ê¸‰ë„ vs ì¤‘ìš”ë„

```
ë†’ì€ ì¤‘ìš”ë„
    â†‘
    â”‚  [Observable LangGraph]     [ì ì‘í˜• RAG]
    â”‚  [ë¶„ì‚° ì²˜ë¦¬]               [ì¥ì•  ë³µêµ¬]
    â”‚  [ë³´ì•ˆ ê°•í™”]
    â”‚
    â”‚  [ì—ì´ì „íŠ¸ í˜‘ì—…]           [ì¸í…”ë¦¬ì „íŠ¸ ìºì‹±]
    â”‚  [ìŠ¤íŠ¸ë¦¬ë° ìµœì í™”]         [ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§]
    â”‚
    â”‚  [ììœ¨ ì—ì´ì „íŠ¸]           [ì—°í•© í•™ìŠµ]
    â”‚  [A/B í…ŒìŠ¤íŒ…]
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
                                    ë†’ì€ ê¸´ê¸‰ë„
```

---

## ğŸ“š ì°¸ê³  ìë£Œ ë° ë„êµ¬

### í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
- **langgraph**: >= 0.2.0
- **langfuse**: ìµœì‹  ë²„ì „ (ê´€ì°° ê°€ëŠ¥ì„±)
- **ray**: >= 2.0.0 (ë¶„ì‚° ì²˜ë¦¬)
- **celery**: >= 5.0.0 (ë¹„ë™ê¸° ì²˜ë¦¬)
- **prometheus-client**: ëª¨ë‹ˆí„°ë§
- **tenacity**: ì¬ì‹œë„ ë¡œì§

### ê°œë°œ ë„êµ¬
- **pytest-benchmark**: ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- **memory-profiler**: ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§
- **locust**: ë¶€í•˜ í…ŒìŠ¤íŠ¸
- **black**: ì½”ë“œ í¬ë§·íŒ…
- **mypy**: íƒ€ì… ì²´í‚¹

### ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ
- **Prometheus**: ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- **Grafana**: ì‹œê°í™”
- **Loki**: ë¡œê·¸ ì§‘ê³„
- **Jaeger**: ë¶„ì‚° ì¶”ì 

---

## ğŸš€ ì‹¤í–‰ ê³„íš (í”„ë¡ íŠ¸ì—”ë“œ í†µí•©)

### Week 1-2: í”„ë¡ íŠ¸ì—”ë“œ ê¸°ì´ˆ ë° ë°±ì—”ë“œ ê°œì„ 
#### í”„ë¡ íŠ¸ì—”ë“œ
- [ ] IBM Carbon Design System ì…‹ì—… ë° í…Œë§ˆ êµ¬ì„±
- [ ] í”„ë¡¬í”„íŠ¸ ì…ë ¥ ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
- [ ] ì—ì´ì „íŠ¸ ì§„í–‰ ìƒí™© ê¸°ë³¸ ì‹œê°í™”
- [ ] ì‹¤ì‹œê°„ ì›Œí¬í”Œë¡œìš° ëª¨ë‹ˆí„°ë§ UI

#### ë°±ì—”ë“œ
- [ ] Observable LangGraph êµ¬í˜„
- [ ] WebSocket ì—”ë“œí¬ì¸íŠ¸ êµ¬ì„±
- [ ] ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìµœì í™”
- [ ] ì—ì´ì „íŠ¸ í˜‘ì—… í”„ë¡œí† ì½œ

### Week 3-4: API í†µí•© ë° ì„±ëŠ¥ ìµœì í™”
#### í”„ë¡ íŠ¸ì—”ë“œ-ë°±ì—”ë“œ í†µí•©
- [ ] WebSocket ì—°ê²° ë° ì‹¤ì‹œê°„ í†µì‹  êµ¬í˜„
- [ ] API í›… ë° ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì—°ê²° ë¡œì§
- [ ] ë¡œë”© ìƒíƒœ ë° í”„ë¡œê·¸ë ˆìŠ¤ ì¸ë””ì¼€ì´í„°

#### ì„±ëŠ¥ ìµœì í™”
- [ ] ì ì‘í˜• RAG ì‹œìŠ¤í…œ
- [ ] ì¸í…”ë¦¬ì „íŠ¸ ìºì‹±
- [ ] ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
- [ ] í”„ë¡ íŠ¸ì—”ë“œ ë²ˆë“¤ ìµœì í™”

### Week 5-6: ê³ ê¸‰ ì‹œê°í™” ë° ì¸í„°ë™ì…˜
#### í”„ë¡ íŠ¸ì—”ë“œ ê³ ê¸‰ ê¸°ëŠ¥
- [ ] D3.js ê¸°ë°˜ Sankey ë‹¤ì´ì–´ê·¸ë¨
- [ ] ì—ì´ì „íŠ¸ ì„±ëŠ¥ íˆíŠ¸ë§µ
- [ ] ë©”íŠ¸ë¦­ìŠ¤ ëŒ€ì‹œë³´ë“œ (Recharts)
- [ ] ì¸í„°ë™í‹°ë¸Œ ì›Œí¬í”Œë¡œìš° í¸ì§‘ê¸°

#### ë°±ì—”ë“œ ê³ ê¸‰ ê¸°ëŠ¥
- [ ] ììœ¨ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
- [ ] ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œìŠ¤í…œ
- [ ] ì›Œí¬í”Œë¡œìš° ì €ì¥ ë° ì¬ì‚¬ìš©

### Week 7-8: ëª¨ë°”ì¼ ëŒ€ì‘ ë° ì ‘ê·¼ì„±
#### í”„ë¡ íŠ¸ì—”ë“œ ìµœì í™”
- [ ] ë°˜ì‘í˜• ë””ìì¸ êµ¬í˜„
- [ ] ëª¨ë°”ì¼ í„°ì¹˜ ì¸í„°í˜ì´ìŠ¤
- [ ] WCAG 2.1 AA ì¤€ìˆ˜
- [ ] í‚¤ë³´ë“œ ë„¤ë¹„ê²Œì´ì…˜ ì§€ì›
- [ ] ìŠ¤í¬ë¦° ë¦¬ë” í˜¸í™˜ì„±

#### ì„±ëŠ¥ ë° UX
- [ ] í”„ë¡œê·¸ë ˆì‹œë¸Œ ë¡œë”©
- [ ] ì˜¤í”„ë¼ì¸ ì§€ì› (PWA)
- [ ] ë‹¤í¬/ë¼ì´íŠ¸ ëª¨ë“œ
- [ ] ë‹¤êµ­ì–´ ì§€ì› ì¤€ë¹„

### Week 9-10: í”„ë¡œë•ì…˜ ì¤€ë¹„
#### í”„ë¡ íŠ¸ì—”ë“œ í”„ë¡œë•ì…˜
- [ ] í”„ë¡œë•ì…˜ ë¹Œë“œ ìµœì í™”
- [ ] CDN ë°°í¬ ì„¤ì •
- [ ] ì—ëŸ¬ ëª¨ë‹ˆí„°ë§ (Sentry)
- [ ] ì• ë„ë¦¬í‹±ìŠ¤ í†µí•©
- [ ] E2E í…ŒìŠ¤íŠ¸ (Playwright)

#### ë°±ì—”ë“œ í”„ë¡œë•ì…˜
- [ ] ë¶„ì‚° ì²˜ë¦¬ êµ¬í˜„
- [ ] ì¥ì•  ë³µêµ¬ ì‹œìŠ¤í…œ
- [ ] ë³´ì•ˆ ê°•í™”
- [ ] ë¡œë“œ ë°¸ëŸ°ì‹±
- [ ] ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

### Week 11-12: í†µí•© í…ŒìŠ¤íŠ¸ ë° ë°°í¬
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹
- [ ] ë³´ì•ˆ ê°ì‚¬
- [ ] ì‚¬ìš©ì ìˆ˜ìš© í…ŒìŠ¤íŠ¸ (UAT)
- [ ] ë‹¨ê³„ì  ë°°í¬ (Canary/Blue-Green)
- [ ] ë¬¸ì„œí™” ë° ìš´ì˜ ê°€ì´ë“œ

## ğŸ“Š í”„ë¡ íŠ¸ì—”ë“œ ê¸°ìˆ  ìŠ¤íƒ

### í•µì‹¬ í”„ë ˆì„ì›Œí¬
- **React 18+**: UI í”„ë ˆì„ì›Œí¬
- **TypeScript**: íƒ€ì… ì•ˆì •ì„±
- **Vite**: ë¹Œë“œ ë„êµ¬
- **React Query**: ì„œë²„ ìƒíƒœ ê´€ë¦¬
- **Zustand**: í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ ê´€ë¦¬

### UI/UX ë¼ì´ë¸ŒëŸ¬ë¦¬
- **IBM Carbon Design System**: ë””ìì¸ ì‹œìŠ¤í…œ
- **D3.js**: ê³ ê¸‰ ì‹œê°í™”
- **Recharts**: ì°¨íŠ¸ ì»´í¬ë„ŒíŠ¸
- **Framer Motion**: ì• ë‹ˆë©”ì´ì…˜

### ê°œë°œ ë„êµ¬
- **ESLint/Prettier**: ì½”ë“œ í’ˆì§ˆ
- **Storybook**: ì»´í¬ë„ŒíŠ¸ ë¬¸ì„œí™”
- **Playwright**: E2E í…ŒìŠ¤íŒ…
- **Vitest**: ìœ ë‹› í…ŒìŠ¤íŒ…

### í”„ë¡œë•ì…˜ ë„êµ¬
- **Sentry**: ì—ëŸ¬ ëª¨ë‹ˆí„°ë§
- **Google Analytics**: ì‚¬ìš©ì ë¶„ì„
- **Lighthouse CI**: ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- **Cloudflare**: CDN ë° ë³´ì•ˆ

---

ì´ ë¡œë“œë§µì„ ë”°ë¼ êµ¬í˜„í•˜ë©´ Project MaestroëŠ” ì—…ê³„ ìµœê³  ìˆ˜ì¤€ì˜ AI ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í”Œë«í¼ìœ¼ë¡œ ì§„í™”í•  ê²ƒì…ë‹ˆë‹¤.