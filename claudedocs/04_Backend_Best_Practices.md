# Python ê¸°ì´ˆë¶€í„° ë§ˆìŠ¤í„°ê¹Œì§€ - 4ë‹¨ê³„: ë°±ì—”ë“œ ê°œë°œ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

## ëª©ì°¨
1. [í…ŒìŠ¤íŠ¸ ì£¼ë„ ê°œë°œ (TDD)](#í…ŒìŠ¤íŠ¸-ì£¼ë„-ê°œë°œ-tdd)
2. [ì½”ë“œ í’ˆì§ˆê³¼ ì •ì  ë¶„ì„](#ì½”ë“œ-í’ˆì§ˆê³¼-ì •ì -ë¶„ì„)
3. [ë³´ì•ˆ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤](#ë³´ì•ˆ-ë² ìŠ¤íŠ¸-í”„ë™í‹°ìŠ¤)
4. [ì„±ëŠ¥ ìµœì í™” ê¸°ë²•](#ì„±ëŠ¥-ìµœì í™”-ê¸°ë²•)
5. [CI/CD íŒŒì´í”„ë¼ì¸](#cicd-íŒŒì´í”„ë¼ì¸)
6. [í”„ë¡œë•ì…˜ ìš´ì˜ ì „ëµ](#í”„ë¡œë•ì…˜-ìš´ì˜-ì „ëµ)

---

## í…ŒìŠ¤íŠ¸ ì£¼ë„ ê°œë°œ (TDD)

### Pytest ê¸°ë°˜ í…ŒìŠ¤íŠ¸ êµ¬ì¡°

```python
# tests/conftest.py - í…ŒìŠ¤íŠ¸ ì„¤ì • ë° í”½ìŠ¤ì²˜
import pytest
import asyncio
from unittest.mock import AsyncMock, MagicMock

# í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •
os.environ["MAESTRO_ENVIRONMENT"] = "test"
os.environ["MAESTRO_DEBUG"] = "true"

class MockLLM(BaseLanguageModel):
    """í…ŒìŠ¤íŠ¸ìš© ëª¨ì˜ LLM"""
    def __init__(self, responses: list = None):
        self.responses = responses or ["Test response"]
        self.call_count = 0

    async def _agenerate(self, messages, **kwargs):
        response = self.responses[self.call_count % len(self.responses)]
        self.call_count += 1
        return AIMessage(content=response)

@pytest.fixture
async def test_db():
    """í…ŒìŠ¤íŠ¸ ë°ì´í„°ë² ì´ìŠ¤ í”½ìŠ¤ì²˜"""
    # í…ŒìŠ¤íŠ¸ DB ìƒì„±
    test_engine = create_async_engine("sqlite+aiosqlite:///:memory:")
    async with test_engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)

    yield test_engine

    # ì •ë¦¬
    await test_engine.dispose()

@pytest.fixture
def mock_agent_registry():
    """ëª¨ì˜ ì—ì´ì „íŠ¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬"""
    registry = MagicMock()
    registry.get_agents_by_type.return_value = [MagicMock()]
    return registry
```

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ

```python
# tests/test_agent_framework.py
import pytest
from unittest.mock import AsyncMock, patch

class TestOrchestratorAgent:
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸"""

    @pytest.mark.asyncio
    async def test_task_execution(self, mock_llm):
        """íƒœìŠ¤í¬ ì‹¤í–‰ í…ŒìŠ¤íŠ¸"""
        # Given
        agent = OrchestratorAgent()
        agent.llm = mock_llm

        task = AgentTask(
            id="test-task-001",
            type="project_analysis",
            description="Analyze game design document",
            parameters={"gdd_content": "Test game design"}
        )

        # When
        result = await agent.execute_task(task)

        # Then
        assert result is not None
        assert "analysis" in result
        assert mock_llm.call_count == 1

    @pytest.mark.asyncio
    async def test_workflow_creation(self, mock_llm):
        """ì›Œí¬í”Œë¡œìš° ìƒì„± í…ŒìŠ¤íŠ¸"""
        # Given
        agent = OrchestratorAgent()
        agent.llm = mock_llm

        project_spec = ProjectSpec(
            id="test-project",
            title="Test Game",
            description="Test description",
            genre="action",
            art_style="pixel",
            gameplay_mechanics=["jump", "shoot"]
        )

        # When
        workflow = await agent.create_workflow(project_spec)

        # Then
        assert len(workflow.steps) > 0
        assert workflow.project_id == "test-project"
        assert any(step.agent_type == AgentType.CANVAS for step in workflow.steps)

    def test_capabilities_definition(self):
        """ì—ì´ì „íŠ¸ ëŠ¥ë ¥ ì •ì˜ í…ŒìŠ¤íŠ¸"""
        # Given
        agent = OrchestratorAgent()

        # When
        capabilities = agent.get_capabilities()

        # Then
        expected_capabilities = [
            "project_analysis",
            "workflow_creation",
            "task_assignment",
            "progress_tracking"
        ]
        assert all(cap in capabilities for cap in expected_capabilities)
```

### í†µí•© í…ŒìŠ¤íŠ¸

```python
# tests/integration/test_project_workflow.py
import pytest
from httpx import AsyncClient

class TestProjectWorkflowIntegration:
    """í”„ë¡œì íŠ¸ ì›Œí¬í”Œë¡œìš° í†µí•© í…ŒìŠ¤íŠ¸"""

    @pytest.mark.asyncio
    async def test_complete_project_creation_flow(self, test_client, test_db):
        """ì „ì²´ í”„ë¡œì íŠ¸ ìƒì„± í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        # Given
        project_data = {
            "title": "Integration Test Game",
            "description": "Test game for integration testing",
            "game_design_document": "A simple platformer game with jumping mechanics..."
        }

        # When - í”„ë¡œì íŠ¸ ìƒì„± ìš”ì²­
        response = await test_client.post("/api/v1/projects/", json=project_data)

        # Then - í”„ë¡œì íŠ¸ ìƒì„± í™•ì¸
        assert response.status_code == 201
        project = response.json()
        assert project["title"] == project_data["title"]
        assert project["status"] == "processing"

        project_id = project["id"]

        # When - í”„ë¡œì íŠ¸ ìƒíƒœ í™•ì¸ (ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ë£Œ ëŒ€ê¸°)
        import asyncio
        await asyncio.sleep(2)  # ì‹¤ì œë¡œëŠ” pollingì´ë‚˜ webhook ì‚¬ìš©

        response = await test_client.get(f"/api/v1/projects/{project_id}")

        # Then - ì²˜ë¦¬ ì™„ë£Œ í™•ì¸
        assert response.status_code == 200
        updated_project = response.json()
        assert updated_project["status"] in ["completed", "processing"]

    @pytest.mark.asyncio
    async def test_agent_collaboration(self, test_client, mock_agent_registry):
        """ì—ì´ì „íŠ¸ í˜‘ì—… í…ŒìŠ¤íŠ¸"""
        with patch('project_maestro.core.agent_framework.agent_registry', mock_agent_registry):
            # Given
            project_data = {"title": "Agent Test", "game_design_document": "Test GDD"}

            # When
            response = await test_client.post("/api/v1/projects/", json=project_data)

            # Then
            assert response.status_code == 201
            # ì—ì´ì „íŠ¸ í˜¸ì¶œ í™•ì¸
            mock_agent_registry.get_agents_by_type.assert_called()
```

### í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ì™€ ë¦¬í¬íŒ…

```python
# pytest.ini ì„¤ì •
[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]
addopts = [
    "--strict-markers",
    "--cov=src/project_maestro",
    "--cov-report=term-missing:skip-covered",
    "--cov-report=html",
    "--cov-report=xml",
    "--cov-fail-under=80"  # 80% ì´ìƒ ì»¤ë²„ë¦¬ì§€ ìš”êµ¬
]
markers = [
    "unit: Unit tests",
    "integration: Integration tests",
    "e2e: End-to-end tests",
    "slow: Slow running tests",
]

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ëª…ë ¹ì–´
# pytest                          # ëª¨ë“  í…ŒìŠ¤íŠ¸
# pytest -m unit                  # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë§Œ
# pytest -m "not slow"           # ëŠë¦° í…ŒìŠ¤íŠ¸ ì œì™¸
# pytest --cov-report=html       # HTML ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸
```

---

## ì½”ë“œ í’ˆì§ˆê³¼ ì •ì  ë¶„ì„

### Black + isort + mypy ì„¤ì •

```toml
# pyproject.toml ì½”ë“œ í’ˆì§ˆ ë„êµ¬ ì„¤ì •

[tool.black]
line-length = 88
target-version = ['py311']
include = '\.pyi?$'
extend-exclude = '''
/(
  \.eggs
  | \.git
  | \.mypy_cache
  | \.venv
  | build
  | dist
)/
'''

[tool.isort]
profile = "black"
multi_line_output = 3
line_length = 88
known_first_party = ["project_maestro"]

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
```

### íƒ€ì… íŒíŠ¸ í™œìš©

```python
# ì™„ì „í•œ íƒ€ì… íŒíŠ¸ ì˜ˆì‹œ
from typing import TypeVar, Generic, Protocol, Union, Literal
from dataclasses import dataclass
from abc import ABC, abstractmethod

T = TypeVar('T')
U = TypeVar('U', bound='BaseAgent')

class Repository(Protocol, Generic[T]):
    """ë¦¬í¬ì§€í† ë¦¬ í”„ë¡œí† ì½œ"""
    async def create(self, entity: T) -> T: ...
    async def get_by_id(self, id: str) -> T | None: ...
    async def update(self, entity: T) -> T: ...
    async def delete(self, id: str) -> bool: ...

@dataclass
class Result(Generic[T]):
    """ê²°ê³¼ ë˜í¼ í´ë˜ìŠ¤"""
    success: bool
    data: T | None = None
    error: str | None = None

    @classmethod
    def ok(cls, data: T) -> 'Result[T]':
        return cls(success=True, data=data)

    @classmethod
    def error(cls, message: str) -> 'Result[T]':
        return cls(success=False, error=message)

# ë¦¬í„°ëŸ´ íƒ€ì… í™œìš©
ProjectStatus = Literal["draft", "processing", "completed", "failed"]

class ProjectService:
    """íƒ€ì… ì•ˆì „í•œ í”„ë¡œì íŠ¸ ì„œë¹„ìŠ¤"""

    def __init__(self, repository: Repository[Project]):
        self.repository = repository

    async def create_project(
        self,
        title: str,
        gdd_content: str,
        target_platform: Literal["mobile", "web", "desktop"] = "mobile"
    ) -> Result[Project]:
        """í”„ë¡œì íŠ¸ ìƒì„±"""
        try:
            project = Project(
                id=str(uuid.uuid4()),
                title=title,
                gdd_content=gdd_content,
                target_platform=target_platform,
                status="draft"
            )

            created_project = await self.repository.create(project)
            return Result.ok(created_project)

        except Exception as e:
            return Result.error(f"í”„ë¡œì íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")

    async def update_status(
        self,
        project_id: str,
        status: ProjectStatus
    ) -> Result[Project]:
        """í”„ë¡œì íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        project = await self.repository.get_by_id(project_id)
        if not project:
            return Result.error("í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        project.status = status
        updated_project = await self.repository.update(project)
        return Result.ok(updated_project)
```

### Pre-commit Hooks

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files

  - repo: https://github.com/psf/black
    rev: 23.12.1
    hooks:
      - id: black
        language_version: python3.11

  - repo: https://github.com/pycqa/isort
    rev: 5.13.2
    hooks:
      - id: isort

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.8.0
    hooks:
      - id: mypy
        additional_dependencies: [types-all]

  - repo: https://github.com/pycqa/flake8
    rev: 6.1.0
    hooks:
      - id: flake8
        args: [--max-line-length=88, --extend-ignore=E203,W503]
```

---

## ë³´ì•ˆ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬

```python
# ë³´ì•ˆ ì„¤ì •
from passlib.context import CryptContext
from jose import JWTError, jwt
from datetime import datetime, timedelta

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

class SecurityManager:
    """ë³´ì•ˆ ê´€ë¦¬ì"""

    def __init__(self, secret_key: str, algorithm: str = "HS256"):
        self.secret_key = secret_key
        self.algorithm = algorithm

    def create_access_token(self, data: dict, expires_delta: timedelta | None = None):
        """ì•¡ì„¸ìŠ¤ í† í° ìƒì„±"""
        to_encode = data.copy()
        if expires_delta:
            expire = datetime.utcnow() + expires_delta
        else:
            expire = datetime.utcnow() + timedelta(minutes=15)

        to_encode.update({"exp": expire})
        encoded_jwt = jwt.encode(to_encode, self.secret_key, algorithm=self.algorithm)
        return encoded_jwt

    def verify_token(self, token: str) -> dict | None:
        """í† í° ê²€ì¦"""
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            return payload
        except JWTError:
            return None

# FastAPI ì˜ì¡´ì„±
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer

security = HTTPBearer()

async def get_current_user(token: str = Depends(security)) -> User:
    """í˜„ì¬ ì‚¬ìš©ì ì¡°íšŒ"""
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )

    payload = security_manager.verify_token(token.credentials)
    if payload is None:
        raise credentials_exception

    user_id = payload.get("sub")
    if user_id is None:
        raise credentials_exception

    user = await user_repository.get_by_id(user_id)
    if user is None:
        raise credentials_exception

    return user

# ë³´í˜¸ëœ ì—”ë“œí¬ì¸íŠ¸
@router.get("/protected")
async def protected_endpoint(current_user: User = Depends(get_current_user)):
    """ë³´í˜¸ëœ ì—”ë“œí¬ì¸íŠ¸"""
    return {"message": f"Hello {current_user.username}"}
```

### ì…ë ¥ ê²€ì¦ ë° SQL ì¸ì ì…˜ ë°©ì§€

```python
from pydantic import BaseModel, validator, Field
from sqlalchemy import text
import re

class ProjectCreateRequest(BaseModel):
    """ì•ˆì „í•œ í”„ë¡œì íŠ¸ ìƒì„± ìš”ì²­"""
    title: str = Field(..., min_length=1, max_length=200)
    description: str = Field(..., max_length=2000)
    gdd_content: str = Field(..., min_length=100)

    @validator('title')
    def validate_title(cls, v):
        # XSS ë°©ì§€
        if re.search(r'[<>"\']', v):
            raise ValueError('ì œëª©ì— íŠ¹ìˆ˜ë¬¸ìê°€ í¬í•¨ë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
        return v.strip()

    @validator('gdd_content')
    def validate_gdd_content(cls, v):
        # ì•…ì„± ìŠ¤í¬ë¦½íŠ¸ íƒì§€
        dangerous_patterns = [
            r'<script',
            r'javascript:',
            r'onclick=',
            r'onerror='
        ]
        for pattern in dangerous_patterns:
            if re.search(pattern, v, re.IGNORECASE):
                raise ValueError('í—ˆìš©ë˜ì§€ ì•ŠëŠ” ë‚´ìš©ì´ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤')
        return v

# íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬ (SQL ì¸ì ì…˜ ë°©ì§€)
class ProjectRepository:
    """ì•ˆì „í•œ ë¦¬í¬ì§€í† ë¦¬"""

    async def search_projects(self, search_term: str) -> List[Project]:
        """ì•ˆì „í•œ í”„ë¡œì íŠ¸ ê²€ìƒ‰"""
        # íŒŒë¼ë¯¸í„° ë°”ì¸ë”© ì‚¬ìš© (SQL ì¸ì ì…˜ ë°©ì§€)
        query = text("""
            SELECT * FROM projects
            WHERE title ILIKE :search_term
            OR description ILIKE :search_term
        """)

        result = await self.session.execute(
            query,
            {"search_term": f"%{search_term}%"}
        )
        return result.fetchall()

    async def get_user_projects(self, user_id: str) -> List[Project]:
        """ì‚¬ìš©ìë³„ í”„ë¡œì íŠ¸ ì¡°íšŒ (ê¶Œí•œ í™•ì¸)"""
        # SQLAlchemy ORM ì‚¬ìš© (ì•ˆì „í•¨)
        query = select(Project).where(
            Project.user_id == user_id
        )
        result = await self.session.execute(query)
        return result.scalars().all()
```

### ì‹œí¬ë¦¿ ê´€ë¦¬

```python
# í™˜ê²½ë³€ìˆ˜ ë° ì‹œí¬ë¦¿ ê´€ë¦¬
from pydantic_settings import BaseSettings
import secrets

class Settings(BaseSettings):
    """ë³´ì•ˆì´ ê³ ë ¤ëœ ì„¤ì •"""

    # ì‹œí¬ë¦¿ í‚¤ (í™˜ê²½ë³€ìˆ˜ì—ì„œë§Œ ì½ê¸°)
    secret_key: str = Field(..., env="SECRET_KEY")
    database_url: str = Field(..., env="DATABASE_URL")

    # API í‚¤ë“¤ (ì˜µì…”ë„, í™˜ê²½ë³€ìˆ˜ ìš°ì„ )
    openai_api_key: str | None = Field(None, env="OPENAI_API_KEY")
    anthropic_api_key: str | None = Field(None, env="ANTHROPIC_API_KEY")

    # ê°œë°œí™˜ê²½ ê¸°ë³¸ê°’, í”„ë¡œë•ì…˜ì—ì„œëŠ” í™˜ê²½ë³€ìˆ˜ í•„ìˆ˜
    redis_url: str = Field(default="redis://localhost:6379", env="REDIS_URL")

    @validator('secret_key')
    def validate_secret_key(cls, v):
        if len(v) < 32:
            raise ValueError('SECRET_KEYëŠ” ìµœì†Œ 32ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤')
        return v

    class Config:
        env_file = ".env"
        env_file_encoding = 'utf-8'

# ì‹œí¬ë¦¿ í‚¤ ìƒì„± ìœ í‹¸ë¦¬í‹°
def generate_secret_key():
    """ì•ˆì „í•œ ì‹œí¬ë¦¿ í‚¤ ìƒì„±"""
    return secrets.token_urlsafe(32)

# .env íŒŒì¼ (ì ˆëŒ€ Gitì— ì»¤ë°‹í•˜ì§€ ì•ŠìŒ)
# SECRET_KEY=your-super-secret-key-here-32-chars-min
# DATABASE_URL=postgresql+asyncpg://user:pass@localhost/db
# OPENAI_API_KEY=sk-...
```

---

## ì„±ëŠ¥ ìµœì í™” ê¸°ë²•

### ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”

```python
# ì¸ë±ìŠ¤ ë° ì¿¼ë¦¬ ìµœì í™”
from sqlalchemy import Index, func
from sqlalchemy.orm import selectinload, joinedload

class Project(Base):
    __tablename__ = "projects"

    id = Column(UUID, primary_key=True)
    title = Column(String(200), nullable=False)
    status = Column(String(50), default="draft")
    user_id = Column(UUID, ForeignKey("users.id"))
    created_at = Column(DateTime, default=datetime.utcnow)

    # ë³µí•© ì¸ë±ìŠ¤ ì •ì˜
    __table_args__ = (
        Index('idx_user_status', 'user_id', 'status'),
        Index('idx_created_at', 'created_at'),
    )

class OptimizedProjectRepository:
    """ìµœì í™”ëœ í”„ë¡œì íŠ¸ ë¦¬í¬ì§€í† ë¦¬"""

    async def get_user_projects_with_assets(self, user_id: str) -> List[Project]:
        """ê´€ë ¨ ìì‚°ê³¼ í•¨ê»˜ í”„ë¡œì íŠ¸ ì¡°íšŒ (N+1 ë¬¸ì œ í•´ê²°)"""
        query = select(Project).options(
            selectinload(Project.assets),  # ë³„ë„ ì¿¼ë¦¬ë¡œ ë¡œë“œ
            joinedload(Project.user)       # JOINìœ¼ë¡œ ë¡œë“œ
        ).where(Project.user_id == user_id)

        result = await self.session.execute(query)
        return result.unique().scalars().all()

    async def get_project_statistics(self) -> Dict[str, int]:
        """ì§‘ê³„ ì¿¼ë¦¬ ìµœì í™”"""
        query = select(
            func.count(Project.id).label('total'),
            func.count(Project.id).filter(Project.status == 'completed').label('completed'),
            func.count(Project.id).filter(Project.status == 'processing').label('processing')
        )

        result = await self.session.execute(query)
        row = result.first()

        return {
            'total': row.total,
            'completed': row.completed,
            'processing': row.processing
        }

# ì—°ê²° í’€ ìµœì í™”
engine = create_async_engine(
    settings.database_url,
    pool_size=20,           # ê¸°ë³¸ ì—°ê²° ìˆ˜
    max_overflow=30,        # ì¶”ê°€ ì—°ê²° ìˆ˜
    pool_pre_ping=True,     # ì—°ê²° ìƒíƒœ í™•ì¸
    pool_recycle=3600,      # 1ì‹œê°„ë§ˆë‹¤ ì—°ê²° ì¬ìƒì„±
    echo=False              # í”„ë¡œë•ì…˜ì—ì„œëŠ” False
)
```

### ìºì‹± ì „ëµ

```python
# ë‹¤ì¸µ ìºì‹± ì‹œìŠ¤í…œ
from functools import wraps
import asyncio

def cache_with_ttl(ttl: int = 300, cache_layer: str = "redis"):
    """TTL ê¸°ë°˜ ìºì‹± ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = f"{func.__name__}:{hash(str(args) + str(kwargs))}"

            # ìºì‹œì—ì„œ ì¡°íšŒ
            cached_result = await cache.get(cache_key)
            if cached_result is not None:
                return cached_result

            # ìºì‹œ ë¯¸ìŠ¤ ì‹œ ì‹¤í–‰
            result = await func(*args, **kwargs)

            # ìºì‹œì— ì €ì¥
            await cache.set(cache_key, result, ttl)

            return result
        return wrapper
    return decorator

class SmartCache:
    """ì§€ëŠ¥í˜• ìºì‹± ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.memory_cache = {}  # ë©”ëª¨ë¦¬ ìºì‹œ
        self.redis_cache = RedisCache()  # Redis ìºì‹œ

    @cache_with_ttl(ttl=600)
    async def get_project_analysis(self, project_id: str) -> Dict:
        """í”„ë¡œì íŠ¸ ë¶„ì„ ê²°ê³¼ ìºì‹±"""
        # ì‹¤ì œ ë¶„ì„ ë¡œì§ (ë¬´ê±°ìš´ ì‘ì—…)
        project = await project_repository.get_by_id(project_id)
        analysis = await complex_analysis_service.analyze(project)
        return analysis

    async def invalidate_project_cache(self, project_id: str):
        """í”„ë¡œì íŠ¸ ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”"""
        patterns = [
            f"get_project_analysis:*{project_id}*",
            f"project_details:*{project_id}*",
            f"project_assets:*{project_id}*"
        ]

        for pattern in patterns:
            await self.redis_cache.delete_pattern(pattern)
```

### ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™”

```python
# ë°°ì¹˜ ì²˜ë¦¬ ë° ë³‘ë ¬ ì‹¤í–‰
import asyncio
from typing import List
from concurrent.futures import ThreadPoolExecutor

class BatchProcessor:
    """ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”"""

    def __init__(self, batch_size: int = 10, max_workers: int = 4):
        self.batch_size = batch_size
        self.executor = ThreadPoolExecutor(max_workers=max_workers)

    async def process_projects_batch(self, project_ids: List[str]) -> List[Dict]:
        """í”„ë¡œì íŠ¸ ë°°ì¹˜ ì²˜ë¦¬"""
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¶„í• 
        batches = [
            project_ids[i:i + self.batch_size]
            for i in range(0, len(project_ids), self.batch_size)
        ]

        # ë³‘ë ¬ ì²˜ë¦¬
        tasks = [
            self._process_single_batch(batch)
            for batch in batches
        ]

        batch_results = await asyncio.gather(*tasks, return_exceptions=True)

        # ê²°ê³¼ ë³‘í•©
        all_results = []
        for result in batch_results:
            if isinstance(result, Exception):
                logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {result}")
                continue
            all_results.extend(result)

        return all_results

    async def _process_single_batch(self, project_ids: List[str]) -> List[Dict]:
        """ë‹¨ì¼ ë°°ì¹˜ ì²˜ë¦¬"""
        # CPU ì§‘ì•½ì  ì‘ì—…ì€ ìŠ¤ë ˆë“œ í’€ì—ì„œ ì‹¤í–‰
        loop = asyncio.get_event_loop()

        cpu_tasks = [
            loop.run_in_executor(
                self.executor,
                self._cpu_intensive_analysis,
                project_id
            )
            for project_id in project_ids
        ]

        # I/O ì§‘ì•½ì  ì‘ì—…ì€ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
        io_tasks = [
            self._io_intensive_fetch(project_id)
            for project_id in project_ids
        ]

        # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
        cpu_results = await asyncio.gather(*cpu_tasks)
        io_results = await asyncio.gather(*io_tasks)

        # ê²°ê³¼ ì¡°í•©
        return [
            {"cpu": cpu, "io": io}
            for cpu, io in zip(cpu_results, io_results)
        ]

# ì»¤ë„¥ì…˜ í’€ ê´€ë¦¬
class ConnectionManager:
    """ì—°ê²° ê´€ë¦¬ì"""

    def __init__(self):
        self.semaphore = asyncio.Semaphore(100)  # ë™ì‹œ ì—°ê²° ì œí•œ

    async def bounded_request(self, url: str) -> Dict:
        """ì œí•œëœ ë™ì‹œ ìš”ì²­"""
        async with self.semaphore:
            async with aiohttp.ClientSession() as session:
                async with session.get(url) as response:
                    return await response.json()
```

---

## CI/CD íŒŒì´í”„ë¼ì¸

### GitHub Actions ì›Œí¬í”Œë¡œìš°

```yaml
# .github/workflows/ci.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: "3.11"
  POETRY_VERSION: "1.7.1"

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_maestro
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: ${{ env.POETRY_VERSION }}

    - name: Install dependencies
      run: |
        poetry install --with dev

    - name: Run linting
      run: |
        poetry run black --check .
        poetry run isort --check-only .
        poetry run flake8 .
        poetry run mypy src/

    - name: Run tests
      env:
        DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost/test_maestro
        REDIS_URL: redis://localhost:6379/0
        SECRET_KEY: test-secret-key-for-ci-only
      run: |
        poetry run pytest --cov=src/ --cov-report=xml

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  security:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Run security scan
      uses: pypa/gh-action-pip-audit@v1.0.8

    - name: Run Bandit security lint
      run: |
        pip install bandit
        bandit -r src/ -f json -o bandit-report.json

  build:
    needs: [test, security]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Login to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: true
        tags: |
          ghcr.io/${{ github.repository }}:latest
          ghcr.io/${{ github.repository }}:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production

    steps:
    - name: Deploy to production
      run: |
        echo "ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰"
        # ì‹¤ì œ ë°°í¬ ë¡œì§
```

### Docker ìµœì í™”

```dockerfile
# Dockerfile - ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œ
FROM python:3.11-slim as builder

# ë¹Œë“œ ì˜ì¡´ì„± ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Poetry ì„¤ì¹˜
RUN pip install poetry

# ì˜ì¡´ì„± íŒŒì¼ ë³µì‚¬
COPY pyproject.toml poetry.lock ./

# ì˜ì¡´ì„± ì„¤ì¹˜ (ê°€ìƒí™˜ê²½ ë¹„í™œì„±í™”)
RUN poetry config virtualenvs.create false \
    && poetry install --only=main --no-root

# í”„ë¡œë•ì…˜ ì´ë¯¸ì§€
FROM python:3.11-slim as production

# ëŸ°íƒ€ì„ ì˜ì¡´ì„±ë§Œ ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# ë¹Œë”ì—ì„œ Python íŒ¨í‚¤ì§€ ë³µì‚¬
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY --from=builder /usr/local/bin /usr/local/bin

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‚¬ìš©ì ìƒì„±
RUN useradd --create-home --shell /bin/bash maestro
USER maestro
WORKDIR /home/maestro

# ì†ŒìŠ¤ ì½”ë“œ ë³µì‚¬
COPY --chown=maestro:maestro src/ ./src/
COPY --chown=maestro:maestro pyproject.toml ./

# í—¬ìŠ¤ì²´í¬ ì¶”ê°€
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
EXPOSE 8000
CMD ["uvicorn", "src.project_maestro.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

## í”„ë¡œë•ì…˜ ìš´ì˜ ì „ëµ

### ëª¨ë‹ˆí„°ë§ê³¼ ì•Œë¦¼

```python
# í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§ ì„¤ì •
from prometheus_client import start_http_server, Counter, Histogram, Gauge
import asyncio
import logging

class ProductionMonitoring:
    """í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§"""

    def __init__(self):
        # ë©”íŠ¸ë¦­ ì •ì˜
        self.http_requests = Counter(
            'http_requests_total',
            'Total HTTP requests',
            ['method', 'endpoint', 'status']
        )

        self.response_time = Histogram(
            'http_response_time_seconds',
            'HTTP response time'
        )

        self.active_connections = Gauge(
            'active_database_connections',
            'Number of active database connections'
        )

        # ì•Œë¦¼ ì„¤ì •
        self.alert_thresholds = {
            'error_rate': 0.05,  # 5% ì˜¤ë¥˜ìœ¨
            'response_time': 2.0,  # 2ì´ˆ ì‘ë‹µ ì‹œê°„
            'memory_usage': 0.85   # 85% ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
        }

    async def check_system_health(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
        while True:
            try:
                # CPU, ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  í™•ì¸
                cpu_usage = psutil.cpu_percent()
                memory_usage = psutil.virtual_memory().percent / 100

                # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸
                db_connections = await self._check_db_connections()

                # ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ì•Œë¦¼
                if memory_usage > self.alert_thresholds['memory_usage']:
                    await self._send_alert(
                        "HIGH_MEMORY_USAGE",
                        f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {memory_usage:.1%}"
                    )

                # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                self.active_connections.set(db_connections)

            except Exception as e:
                logger.error(f"ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")

            await asyncio.sleep(30)  # 30ì´ˆë§ˆë‹¤ í™•ì¸

    async def _send_alert(self, alert_type: str, message: str):
        """ì•Œë¦¼ ì „ì†¡"""
        # Slack, ì´ë©”ì¼, PagerDuty ë“±ìœ¼ë¡œ ì•Œë¦¼
        logger.critical(f"[ALERT] {alert_type}: {message}")

        # ì™¸ë¶€ ì•Œë¦¼ ì„œë¹„ìŠ¤ í˜¸ì¶œ
        await self._notify_slack(alert_type, message)

# ë¡œê·¸ ì§‘ê³„ ì„¤ì • (ELK Stack)
LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'json': {
            'format': '%(asctime)s %(name)s %(levelname)s %(message)s',
            'class': 'pythonjsonlogger.jsonlogger.JsonFormatter'
        }
    },
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'formatter': 'json'
        },
        'file': {
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': '/var/log/maestro/app.log',
            'maxBytes': 100_000_000,  # 100MB
            'backupCount': 5,
            'formatter': 'json'
        }
    },
    'root': {
        'level': 'INFO',
        'handlers': ['console', 'file']
    }
}
```

### ë°°í¬ ì „ëµ

```python
# ë¸”ë£¨-ê·¸ë¦° ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
import subprocess
import time
import requests

class BlueGreenDeployment:
    """ë¸”ë£¨-ê·¸ë¦° ë°°í¬ ê´€ë¦¬"""

    def __init__(self):
        self.blue_port = 8000
        self.green_port = 8001
        self.load_balancer_url = "http://localhost:80"

    async def deploy_new_version(self, image_tag: str):
        """ìƒˆ ë²„ì „ ë°°í¬"""
        try:
            # 1. í˜„ì¬ í™œì„± í™˜ê²½ í™•ì¸
            active_env = await self._get_active_environment()
            inactive_env = "green" if active_env == "blue" else "blue"
            inactive_port = self.green_port if inactive_env == "green" else self.blue_port

            logger.info(f"í˜„ì¬ í™œì„± í™˜ê²½: {active_env}")
            logger.info(f"ë°°í¬ ëŒ€ìƒ í™˜ê²½: {inactive_env}")

            # 2. ë¹„í™œì„± í™˜ê²½ì— ìƒˆ ë²„ì „ ë°°í¬
            await self._deploy_to_environment(inactive_env, image_tag, inactive_port)

            # 3. í—¬ìŠ¤ ì²´í¬
            if not await self._health_check(inactive_port):
                raise Exception("ìƒˆ ë²„ì „ í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨")

            # 4. íŠ¸ë˜í”½ ì ì§„ì  ì „í™˜ (ì¹´ë‚˜ë¦¬ ë°°í¬)
            await self._gradual_traffic_switch(active_env, inactive_env)

            # 5. ì´ì „ í™˜ê²½ ì •ë¦¬
            await self._cleanup_old_environment(active_env)

            logger.info("ë°°í¬ ì™„ë£Œ")

        except Exception as e:
            # ë¡¤ë°±
            logger.error(f"ë°°í¬ ì‹¤íŒ¨: {e}")
            await self._rollback(active_env)
            raise

    async def _deploy_to_environment(self, env: str, image_tag: str, port: int):
        """íŠ¹ì • í™˜ê²½ì— ë°°í¬"""
        # Docker ì»¨í…Œì´ë„ˆ ì‹œì‘
        cmd = [
            "docker", "run", "-d",
            "--name", f"maestro-{env}",
            "-p", f"{port}:8000",
            "-e", f"ENVIRONMENT={env}",
            f"ghcr.io/project-maestro/project-maestro:{image_tag}"
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0:
            raise Exception(f"ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹¤íŒ¨: {result.stderr}")

        # ì»¨í…Œì´ë„ˆ ì‹œì‘ ëŒ€ê¸°
        await asyncio.sleep(10)

    async def _health_check(self, port: int, timeout: int = 60) -> bool:
        """í—¬ìŠ¤ ì²´í¬"""
        url = f"http://localhost:{port}/health"

        for _ in range(timeout):
            try:
                response = requests.get(url, timeout=5)
                if response.status_code == 200:
                    health_data = response.json()
                    if health_data.get("status") == "healthy":
                        return True
            except:
                pass

            await asyncio.sleep(1)

        return False

    async def _gradual_traffic_switch(self, old_env: str, new_env: str):
        """ì ì§„ì  íŠ¸ë˜í”½ ì „í™˜"""
        # 10% â†’ 50% â†’ 100% ë‹¨ê³„ì  ì „í™˜
        traffic_ratios = [10, 50, 100]

        for ratio in traffic_ratios:
            await self._update_load_balancer(new_env, ratio)

            # ëª¨ë‹ˆí„°ë§ ê¸°ê°„
            await asyncio.sleep(300)  # 5ë¶„ ëŒ€ê¸°

            # ì˜¤ë¥˜ìœ¨ í™•ì¸
            error_rate = await self._check_error_rate()
            if error_rate > 0.05:  # 5% ì´ˆê³¼ ì‹œ ë¡¤ë°±
                raise Exception(f"ì˜¤ë¥˜ìœ¨ ì´ˆê³¼: {error_rate:.2%}")

        logger.info("íŠ¸ë˜í”½ ì „í™˜ ì™„ë£Œ")

# Kubernetes ë°°í¬ (Helm ì°¨íŠ¸)
# values.yaml
replicaCount: 3

image:
  repository: ghcr.io/project-maestro/project-maestro
  tag: latest
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 80
  targetPort: 8000

ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
  hosts:
    - host: api.projectmaestro.dev
      paths:
        - path: /
          pathType: Prefix

resources:
  limits:
    cpu: 1000m
    memory: 2Gi
  requests:
    cpu: 500m
    memory: 1Gi

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
```

---

## ë§ˆë¬´ë¦¬: ë°±ì—”ë“œ ë§ˆìŠ¤í„°ë¡œì˜ ì—¬ì •

### í•™ìŠµ ì—¬ì • ìš”ì•½

ì§€ê¸ˆê¹Œì§€ 4ë‹¨ê³„ì— ê±¸ì³ Python ë°±ì—”ë“œ ê°œë°œì˜ ì „ì²´ ìŠ¤í™íŠ¸ëŸ¼ì„ ë‹¤ë¤˜ìŠµë‹ˆë‹¤:

1. **ê¸°ì´ˆ ë‹¨ê³„**: Python ë¬¸ë²•, í•¨ìˆ˜, í´ë˜ìŠ¤, ëª¨ë“ˆ ì‹œìŠ¤í…œ
2. **ê³ ê¸‰ ë‹¨ê³„**: ë¹„ë™ê¸°, ë³‘ë ¬ì²˜ë¦¬, ì˜ˆì™¸ì²˜ë¦¬, ì˜ì¡´ì„± ì£¼ì…
3. **ì•„í‚¤í…ì²˜ ë‹¨ê³„**: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤, ì´ë²¤íŠ¸ ë“œë¦¬ë¸, API ì„¤ê³„
4. **ì‹¤ë¬´ ë‹¨ê³„**: í…ŒìŠ¤íŠ¸, ë³´ì•ˆ, ì„±ëŠ¥, CI/CD, ìš´ì˜

### ì‹¤ë¬´ ì ìš© ì²´í¬ë¦¬ìŠ¤íŠ¸

**ê°œë°œ ì¤€ë¹„**
- [ ] ê°œë°œí™˜ê²½ ì„¤ì • (Poetry, Pre-commit, IDE)
- [ ] í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ê³„ (ë ˆì´ì–´ë“œ ì•„í‚¤í…ì²˜)
- [ ] ì˜ì¡´ì„± ê´€ë¦¬ (pyproject.toml ì„¤ì •)

**ì½”ë“œ í’ˆì§ˆ**
- [ ] íƒ€ì… íŒíŠ¸ 100% ì ìš©
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ 80% ì´ìƒ ì»¤ë²„ë¦¬ì§€
- [ ] ì½”ë“œ ìŠ¤íƒ€ì¼ ìë™í™” (Black, isort)
- [ ] ì •ì  ë¶„ì„ ë„êµ¬ ì ìš© (mypy, flake8)

**ì•„í‚¤í…ì²˜**
- [ ] ë¹„ë™ê¸° ì²˜ë¦¬ ì„¤ê³„
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
- [ ] ìºì‹± ì „ëµ ìˆ˜ë¦½
- [ ] ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•

**ìš´ì˜**
- [ ] CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
- [ ] ì»¨í…Œì´ë„ˆí™” (Docker)
- [ ] ë³´ì•ˆ ê²€ì‚¬ ìë™í™”
- [ ] ë¡œê·¸ ë° ë©”íŠ¸ë¦­ ìˆ˜ì§‘

### ê³„ì† í•™ìŠµí•  ì£¼ì œë“¤

**ì‹¬í™” ì£¼ì œ**
- ë¶„ì‚° ì‹œìŠ¤í…œ ì„¤ê³„ íŒ¨í„´
- ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- ì´ë²¤íŠ¸ ì†Œì‹± ë° CQRS
- ì„œë²„ë¦¬ìŠ¤ ì•„í‚¤í…ì²˜

**ê¸°ìˆ  íŠ¸ë Œë“œ**
- FastAPI ê³ ê¸‰ ê¸°ëŠ¥
- PostgreSQL ì„±ëŠ¥ íŠœë‹
- Kubernetes ìš´ì˜
- ê´€ì°°ê°€ëŠ¥ì„± (Observability)

### í† ë¡  ì¤€ë¹„ ì™„ë£Œ!

ì´ì œ ë‹¤ìŒê³¼ ê°™ì€ ë°±ì—”ë“œ í† ë¡ ì— ìì‹  ìˆê²Œ ì°¸ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ vs ëª¨ë†€ë¦¬ìŠ¤ ì•„í‚¤í…ì²˜ ì„ íƒ ê¸°ì¤€"
- "Python GILì˜ í•œê³„ì™€ í•´ê²°ì±…"
- "ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤ì¼€ì¼ë§ ì „ëµ"
- "API ì„¤ê³„ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤"
- "í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ê³„"
- "DevOps ë¬¸í™”ì™€ CI/CD íŒŒì´í”„ë¼ì¸"

**í† ë¡  ì‹œ í™œìš©í•  ìˆ˜ ìˆëŠ” í‚¤ì›Œë“œë“¤:**
- ì´ë²¤íŠ¸ ë“œë¦¬ë¸ ì•„í‚¤í…ì²˜, CQRS, ì‚¬ê°€ íŒ¨í„´
- ë¹„ë™ê¸° ì²˜ë¦¬, ì—°ê²° í’€ë§, ìºì‹± ì „ëµ
- ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜, ì„œë¹„ìŠ¤ ë©”ì‹œ
- ë¶„ì‚° ì¶”ì , ë©”íŠ¸ë¦­, ë¡œê·¸ ì§‘ê³„
- ë³´ì•ˆ by ì„¤ê³„, ì œë¡œ íŠ¸ëŸ¬ìŠ¤íŠ¸

ì¶•í•˜í•©ë‹ˆë‹¤! ì´ì œ Python ë°±ì—”ë“œ ê°œë°œìë¡œì„œ ì‹¤ë¬´ì—ì„œ ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì¢…í•©ì ì¸ ì§€ì‹ì„ ê°–ì¶”ì…¨ìŠµë‹ˆë‹¤. ğŸ‰